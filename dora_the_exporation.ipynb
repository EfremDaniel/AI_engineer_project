{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86446f20",
   "metadata": {},
   "source": [
    "### Trying to convert markdown into clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e04e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fastapi CRUD app\n",
      "\n",
      "**Kokchun Giang:** [00:00:00] Hello and welcome to this video where we'll go into Fast API in Python. This is a way to create ~~an ~~A ~~PIA ~~rest API and that is what we'll be creating a ~~acru ~~application for. For a library or for books that we can serve books, data. And if you've seen some of my videos before, in a previous video, I used pedantic together with Gemini in order to generate the JSON datas in a structured way.\n",
      "\n",
      "And then I simulated a lot of books data. Now the idea is that I will pick this JSON data and then I will continue on to work and build. An API that we can serve these books to a front end. And then since it's an API, the backend is in Python, we create the backend where we do different data processing.\n",
      "\n",
      "We create the API, which is a layer in between our backend and. Any front end application. You could [00:01:00] use, for example you could use React, you could use Typi, you could use Plotly, you could Plotly Dash, you could use streamlet, et cetera. Or you can use yeah, whatever you want as a front end and just connect to this API.\n",
      "\n",
      "That is the idea. But this is, a very basic one. We'll create a crud application now.\n",
      "\n",
      "**Kokchun Giang-1:** here I am in Visual Studio Code and~~ besides, ~~besides this data here, it's empty. This is from a previous video where we used the Gemini ~~together with ap ~~together with Edan in order to create structured JSON data. And what we did was the library do Jason. Here you can see ulu Library, and here we get all the books.\n",
      "\n",
      "And the only difference is that from that video is that I added IDs. I've added IDs for each of the books. Otherwise, it's the same data as we've gotten from that video. I will link that in the description as well. Otherwise, this is a completely empty repository or completely [00:02:00] empty folder.\n",
      "\n",
      "And we create a terminal here. We'll create a new virtual environment, UVNV, and then Source Van Beam Activate. We activated it. We have fast API crud. This is, we will create the crud, API. That means create, read, update, and delete. In order to do that we will start with installing. UV PIP installed we will need to have let's see, what do we need?\n",
      "\n",
      "We need to have fast API, of course, UV corn to run fast. API. And we need we can start with this one. And if we need something else, we'll install it on the way. Okay, then let's start with creating our A-P-I-A-P dot pi. And here from fast API import fast, API we will also do like this. We will create a.\n",
      "\n",
      "Constance Stance pi, and inside of the [00:03:00] Constance Pi, I need to have the data path. From path lib, import path, remember, we're in normal Python script, and in order to define a path here, we will need to have path lib. Then data path. Data path equals to path of d the file. It's this is path to this constant PI and then dot parent.\n",
      "\n",
      "And then you can, you are in fast, API crud. You can see all of these folders. And I will go into the data folder. Then this data path exists here we can import it in in elsewhere. And also let's see. We will need to have I will need to have another script here. I'll create another script called DataCore Processing pi.\n",
      "\n",
      "The reason for doing this is that I don't want to put everything into my API module. I want to separate it and and make it more [00:04:00] scalable. We will start with reading in the data. Import j we will take from Constance import data path and then we will do def read Jason, and here I'll place in the fine name and with open data path slash fine name.\n",
      "\n",
      "And I want to ~~read it. ~~Read it. We take R as file, and then data equal to js dot load file. And then we return data basically like that. We can try this out. If d the name equals to D the main, then we'll do read Jason. And what do we want to place in? What is this called? It's called Library [00:05:00] Jason.\n",
      "\n",
      "Library J data goes to this, and then I will print the data and I'll run this one. Okay. You can see we have the data here. If we want to print a little bit nicely, we can do from P print, import P print. And then instead of print, I will do p print instead. Clear the terminal and run it again. Okay.\n",
      "\n",
      "Yeah, it still looked, oh. I had print here. P print. Oh yeah. Now it looks better. You can see books. We have. Name also. But in inside of books we have a list of dictionaries. It's a list of dictionaries. Since it's a list of dictionary, we can do it like this. We can create a class called book.\n",
      "\n",
      "This is our model, our book model. And what we need is from P den [00:06:00] import base model. Base model, comma field. And this book, I will call base model. It's it's inheriting base model. It means that this one will become a a edan model, but it's still a normal class. It's a class, but it's a Edan model as well.\n",
      "\n",
      "Id in. You can see inside of books here, it's for each book you can see we have id, we have author, title, and year. Okay. And then we can have title, it's a string. We can have author. It's a string as well. And we have a year. It's an int and this is a field. I want it to be greater than equals to greater than 1000 and less than equals to this year.\n",
      "\n",
      "2025. And to get this year, we can do current year plus one. And [00:07:00] to get the current year let me just go into Constance and we can do from daytime import daytime, and we can do. Current year equals to date time now year. It means that data processing, we can import that from stance import current year.\n",
      "\n",
      "And what this means is that~~ we have a. We, ~~we want it to be larger than, greater than 1000. And we want it to be less than 2026, since it's 2025 now. This current year will become 2025 and plus one, we'll have 2026. Okay? This is our gigantic model and ~~for ~~for our book. ~~And then we can do, also, we can do.~~\n",
      "\n",
      "Class library. It's a base model and the name is String and [00:08:00] Books is list of book, we have this book here that is a model. Library is having the name and it has several books. If you're not familiar with pedantic, make sure to take a look into my pedantic videos ~~before ~~because~~ they will, ~~they are the foundation for fast API fast.\n",
      "\n",
      "API uses pedantic a lot for validating the data. Then we have. Library here, and we can also do like this. We can do deaf library data or file name and then Jason. Jason. Data equals to read Jason. I use the read Jason by placing the fine name and then return library. ~~Model validate ~~model, validate JSON data.\n",
      "\n",
      "Okay, this means that [00:09:00] the library will ~~we, ~~we can do library data. It will read this ~~Jason ~~file. And get this JSON data. And then we'll do library do model validate. This means that instead of doing ~~re ~~json like this, we can try this out by doing library equals to library data of let's see, what's it called?\n",
      "\n",
      "Library J.\n",
      "\n",
      "And we can take a look into library. What does that look like? If I run this one, you can see it's a library object where we have the name Ulu Library, we have books. And we have all the books here. And each of the books contain a book object or a book instance where we have ID title, we have author and year.\n",
      "\n",
      "These [00:10:00] are all ~~edan ~~models. All the book are the models. Library is a pedantic model. That means that we have already validated the data that it comes into the ~~right ~~right fields. We have in string and we have interior with the correct fields here. If you, for example, take a look, for example, if we take 19 ~~hundreds ~~here, we'll have a fail here because you can see there's a lot of books here.\n",
      "\n",
      "Books one year. You can see input should be greater than 1900 books. Five point year input should be greater than 1900, et cetera. And here you can see it's 18 13, 18 51. You can see there is, it's validating the data, but ~~the ~~I want to make it simple. I just take 1000 here. If I run this one, it should be fine because all have years greater than 1000.\n",
      "\n",
      "Okay, for this I'm quite satisfied with the data processing. Let's move on to our API. Inside of the API dot [00:11:00] pi, you start with creating an app equals to fast API. ~~This ~~now we have a fast API application, and then. What we should do also is that we'll read in the data. I can do it before actually library equals to, from data processing, import library data, and we can do library data here.\n",
      "\n",
      "~~Library J. ~~Then we have the library, and then we can get the books. And if you see library to get the books, we do library, do books, library dot books. And basically now you can p print the, ~~let's see, ~~we need to import P print from P print, import, P print. And we can do p print of books. If I just run this one, you can see here are all the books and it's a list of the books.\n",
      "\n",
      "~~Good. ~~And we can now we have our Fast API application and we can create our [00:12:00] first endpoint. At app get. If I go into my URL and I do ~~slash. My first endpoint ~~slash books, I should read all the books, this is a decorator, it'll decorate a function that makes it into ~~a a end ~~an endpoint with the GET request.\n",
      "\n",
      "Get is~~ sim, it's ~~the read operation in crud. Create, read, update, delete. ~~We'll create, ~~this is a get request, then you do async dev and async is to make the the function asynchronous that it doesn't get stuck when when running this one. But fast. API actually makes all the endpoints into async by default, but I type it out to make it extra clear.\n",
      "\n",
      "Async dev read books. Return books basically. Let's try out this endpoint. To try it out, you do like this. You have activated your virtual environment. You have installed UV, corn and [00:13:00] fast API. Let's do UV corn api, pi API Colon app. ~~API is this API. ~~You don't~~ in ~~include the dot pi and then you take what the fast API application's name, which is app, and then that dash reload.\n",
      "\n",
      "You don't need to run it each time you change the code. I run this one and what we get is a server that runs on ~~8,000, ~~port 8,000. ~~I run this one. ~~I will have this side by side. I will make this a little bit bigger and this a little bit smaller like this.\n",
      "\n",
      "Actually, I will have this run out like this. Okay? Right now it says detail not found, but if you do slash books, you can see, ah, these are our books. Wow. Cool. Okay, we can click indented write out the indented code.\n",
      "\n",
      "**Kokchun Giang-2:** Yes. Much cooler. Now it's indented. You can read the data very clearly. Okay, what is the point with [00:14:00] this? When you have it you serve it in API like this. You have a URL, and you can use this URL to do, get request. For example~~ if you ~~if you are in a Jupyter Notebook and you do request on this data.\n",
      "\n",
      "~~You will get this data back. You do request on this URL, ~~you will get this data back and that means that you can serve this to ~~a ~~a frontend application without problems. Let's show you. Another very neat thing is in fast API, there is something called Swagger ui. You go into slash docs and you come into this documentation page here in Fast, API, and you can see there's this get request here.\n",
      "\n",
      "You can click here and you can try it out and you can execute it. And what you can see here is that to do curl. You do type like this and curl is basically what you type in your terminal. If I create a new terminal here and I paste this in this curl, and you can see I get the data. Cool. [00:15:00] And you can, this is the request, URL.\n",
      "\n",
      "As you saw before, we have this URL and then stash books. Then ~~we get into this ~~we get the data we can copy this one and you can see we open here. And you can see we get the data good. And then the response, you can get it here. When you have Swagger ui, you can directly interact with your API through this user interface.\n",
      "\n",
      "And this is really neat. You don't need to have a third party tool such as Postman or some other ~~to ~~tools. You can do it directly here. Okay? Let us continue building on our API. We'll create something called a path parameter. And the path parameter, you should place it before your query parameters.\n",
      "\n",
      "I'll show you what ~~per ~~query parameters is also. App get slash books. We still go into [00:16:00] slash books and then we go into title. And we go into, we type in the title. This is how you do path Parameter. You have curly braces of ~~your your what you want to ~~what the variable should be, what the string should be after the slash title.\n",
      "\n",
      "This one will go into Async f Read book by title. And then you will take the title, it's a string and we should return book for book in books. If book do, title do case fold. Case fold, makes it lowercase equals two. Title case fold. It's lowercase.\n",
      "\n",
      "Let me make it a little bit bigger. What it does is that we have book ~~four ~~[00:17:00] book in books. We get all the books by this title. Where the book, ~~the ~~title equals to. Title case fold. It means that we can type in books with capital letters and it doesn't matter, it will be translated.\n",
      "\n",
      "Let's restart this one. You can see, oh, we get another get request there. Try this out and you can see in Swagger ui you can just type in the title. What title do we have? The Great Gatsby. The great Gaby. Let me just type it like this and show that it works. Anyway, execute, and you can see we get back this de Great Gatsby f Scott Fitzgerald.\n",
      "\n",
      "Okay, here you can see this is the URL there. And then we have percentage, 20, great percentage, 20 Gatsby. Percentage, 20 means [00:18:00] space. This is the URL. If you copy this URL and you go into here, you can see we get this data back. It works. Okay, let's continue. This was a path parameter. You could do ~~per ~~parameters or IDs also if you want.\n",
      "\n",
      "Now let's do a ~~query parameter. ~~Query parameter. It'll, it means that you have a question mark after your endpoint. Start on this, ~~or year ~~I will use this one equals 1950, for example, if you do this. Then this variable start year equals 1950 will be used in our endpoint. At app get slash books slash this one here, we'll go into the books and put in our question mark.\n",
      "\n",
      "Let's [00:19:00] see, async dev filter books ~~and. ~~And what I want to do is start here. This is an int equals to let me import. ~~Query. Query. It's for query, pars ~~query. For default value. This is similar to using the field~~ in in, ~~in pedantic. Query, I want it to be by default, 1950 greater equals to say 1500 less than equals to Let's take current year.\n",
      "\n",
      "From Constance import current year, this equals current year plus one.\n",
      "\n",
      "And then I will also have a description,\n",
      "\n",
      "~~the script, ~~the description equals [00:20:00] to filters, books that are newer than this year. ~~Okay. ~~Okay. Let's see. This is my ~~deaf ~~and I will do filtered books equals to book for book in books. If start year is less than book ~~thought ~~year. Basically like this. Okay, I filter these books and what we do is that we want to return filtered books.\n",
      "\n",
      "Okay? Save this one. Go into swagger, ui, update it. And you can see here we have filter books. I test this out. Okay, try 1950, execute. And you saw that. Okay. We don't get [00:21:00] any books back. Let's see why. Book for book in books. If start year is less than book that year book that year and start year is an int.\n",
      "\n",
      "Oh, I haven't, oh. I have run it. It's, it is run. Okay. I saved this one.\n",
      "\n",
      "Try it out. Filter books that are new than this year. 1950. Execute. I get back nothing. Let me see why. Less than greater than 1500. Less than. 2051. 2026. Filter. This book? Yeah. Oh, okay. Filter book. Ah, filter books. Yeah. I return this function. Of course it doesn't give anything. [00:22:00] Okay. Execute this one and it works.\n",
      "\n",
      "And you can see all of them are newer than 1950. If I take, for example, 90 55 here. We will not get a lot of the rings. If I run this one, we'll only get these two. Okay, great. It works. Now we filter by this, but if you want, you can also, we can see this is the URL, you have slash books, and then we have question marks.\n",
      "\n",
      "Start year equals 90 55. If we want, we can put in more parameters to to query parameters we can have author also if we want. Author is a string. It's a query. None you don't play. It makes it optional. And then we can have a description authors first name and last name. Filter by author's, first name and last name.[00:23:00] \n",
      "\n",
      "Okay, this is the description and we have author and then we can filter the book. If author, it means it's not none, then filtered books equals to this list. Book for book in filtered books. If author.case fold. Equals to book author case fold. Then we return these books here, save this one or update this one.\n",
      "\n",
      "You can see now author comes in as well. Try it out and you can see if we just take 1950 and execute it, it works. ~~Because we haven't ~~because this is it has none as the fault, it's optional. But if I put in an author, for example, Douglas Adams. Douglas Adams [00:24:00] execute it, you can see we get only this one back.\n",
      "\n",
      "Good. This one works. Now we only use the get requests. We are still in read. If we want to create a crud operations, we should do create as well. To do create, we do app post. What you want to do is ~~you want to put in a, ~~you want to post a new book. Books slash create book. And here, async Deaf, great book request.\n",
      "\n",
      "You want to put in a new book as a J object, and this should be book.\n",
      "\n",
      "Okay, and ~~we don't have books, ~~we need to import this one import book. This is the Edan model. It means that it has to conform to the, to, to the fields in the Edan model in order for it to create a new book and then [00:25:00] to create a new book. It's as simple as this new book equals to book model.\n",
      "\n",
      "A ~~book is a, remember the ~~book is a pedantic model, we can ~~do model ~~validate our book request. Just to make sure we turn it into ~~a. ~~A book object. And then what we do is books that append new book. And remember that we append the book. We have our books ~~contains a lot of they ~~contains book objects that are pedantic models.\n",
      "\n",
      "However, when we serve it in the API remember that it gives us ~~chase in ~~data. And what it does is that fast API automatically. ~~It ~~converts it ~~into ~~into JSON data, and that is very good. We have return new book because this is good to do. ~~When you ~~when you basically, you have appended it into your books.\n",
      "\n",
      "That when you do [00:26:00] get request, you will see the new book as well. However when you do post you want to return a new book to show you that it's the new book that is placed in. Let's update this one, and now you can see there's a post. Go into here. We try this out and these are example values you can see.\n",
      "\n",
      "Id zero now. We haven't done ~~any ~~any validation on the id. You could do that. ~~14, ~~for example, title is a string. ~~And what is this? ~~This example is based on our P model. You can see our book model here. It's an int that's why they have a value here, a string. It's also an author.\n",
      "\n",
      "It's also string. You got the value as strings here and int you get this field. Here. ~~Let us make this let us just try or ~~let us make this more helpful. In the documentation. To do that, we go into our data processing and into our book model, [00:27:00] and we'll do something called model config.\n",
      "\n",
      "It's a dictionary, Jason Schema Extra. This is another dictionary. And here we have an example and. Which is non dictionary. And now the example, let's take ID colon 11. We have a title right then with a engineer,\n",
      "\n",
      "author co yang here. 2025. Save this one\n",
      "\n",
      "and let us try it out now. If I update this one, you can see, ah, this is the example values. Good. Try it out. And you can see this example values. Yeah, [00:28:00] we can use this directly. Execute, and you can see that. The response body, it gives back this one. This is the response after we have posted it. Okay.\n",
      "\n",
      "But let's see if this book is there. Read books, try it out, execute. You can see down here. Ah, 11. Learn with Engineer K Young. Okay, cool. Our post request works. And also you can try it out here if you want to read all books.\n",
      "\n",
      "You can see that. Yeah, it's here. Now we have posted the data and let us continue now. We have. Create is post in in fast, API and we can do at app update. This is the update and we can slash books [00:29:00] slash up update book, async dev update book. Updated book. It's a book object, a book model for I book in enumerate books.\n",
      "\n",
      "This means that we'll get indexes for each of the books. And then if book ID equals to Id.\n",
      "\n",
      "Let's see if book ID equals ~~updated book id, ~~updated book id. If this is the case, then books of I equals the updated book. ~~Okay, it means that. We will update ~~we will create~~ when we update we put in ~~a JSON object and the JS ~~O ~~will [00:30:00] take a look into the id. If it's the same ID as another book that exists, then we'll update that book.\n",
      "\n",
      "Otherwise, we won't do anything. After that, we return our updated book. ~~Okay. ~~Fast. API don't let's see. Oh it's not called update. It's called put in fast. API ~~it's called Put. ~~Okay, let us try to change ID 10 here. In my, put, try it out. Let's change Id 10 to. Okay, cool Book. And I've written it, execute it and it returns back this updated book.\n",
      "\n",
      "Let's look into here. This is my slash books here. If I run this one, you can see, ah, I did 10. [00:31:00] Cool book. And why did my 11 disappear? Yeah, because I have reloaded it. Then the data is not stored in the j per se, we haven't done logic for that in, instead it's just for this run here.\n",
      "\n",
      "If you want it to be stored, you should connect it to a database, but I won't show it here. We have done update book. What is left is that we need to delete book. Then we have our cred application. App delete slash books slash delete book slash id. This is a what's called, it's a, puff parameter, async deaf delete book, and it should take in the ID [00:32:00] as an ink and for I comma book in enumerate books. If book id. Equals id. Then we delete this book, books of I Break. Okay, let's try this out. ~~Update this one. ~~Delete id. Let's remove one. Execute.\n",
      "\n",
      "If we go back here and take a look into all the books. You can see ID one has disappeared. Let's remove ID five as well. Five execute. And now we need to rerun this one. Execute. And you can see five has disappeared. Cool. This is our fast API application\n",
      "\n",
      "**Kokchun Giang-3:** We have created our [00:33:00] first CRUD application ~~using ~~using Fast API. ~~And ~~here we have worked with ~~p we have worked with Jason ~~Data and we have created our. ~~Book API ~~books API, that you can read from the books get requests, you can do posts, you can do update, you can do update by put, and you can do deletes.\n",
      "\n",
      "This is ~~really ~~really interesting ~~and ~~and what you can do later with this is that you can connect this into a frontend application. ~~And ~~and then you can, mix and match and use whatever ~~frontend application you want. ~~Frontend framework. You want ~~to do this that ~~if you want to mix Python with JavaScript, no problems.\n",
      "\n",
      "If you want to mix Python with something else, that's no problem either. You can use Python all the way. ~~Also, ~~that's also possible. There's a lot of opportunities when you work with APIs. It's a layer in between now and this is really interesting and I hope. ~~Hope that ~~you have learned a lot from this video ~~and ~~thank you.\n",
      "\n",
      "See you in the next one. Bye.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from backend.constants import DATA_PATH\n",
    "from markdown import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "md_file = next(DATA_PATH.glob(\"*.md\"))\n",
    "\n",
    "with open(md_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    md_text = f.read()\n",
    "\n",
    "print(md_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3080f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_any_duplicates():\n",
    "    duplicates = list(DATA_PATH.glob(\"*(1).md\"))\n",
    "\n",
    "    if duplicates:\n",
    "        for d in duplicates:\n",
    "            print(\"Removing any potential duplicates\")\n",
    "            d.unlink()\n",
    "\n",
    "\n",
    "def convert_md_txt(md_path):\n",
    "\n",
    "    with open(md_path, 'r', encoding=\"utf-8\") as file:\n",
    "        md_text = file.read()\n",
    "\n",
    "        html = markdown(md_text)\n",
    "        who_even_likes_soup = BeautifulSoup(html, features='html.parser')\n",
    "\n",
    "        return who_even_likes_soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65919384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastapi CRUD app\n",
      "Kokchun Giang: [00:00:00] Hello and welcome to this video where we'll go into Fast API in Python. This is a way to create ~~an ~~A ~~PIA ~~rest API and that is what we'll be creating a ~~acru ~~application for. For a library or for books that we can serve books, data. And if you've seen some of my videos before, in a previous video, I used pedantic together with Gemini in order to generate the JSON datas in a structured way.\n",
      "And then I simulated a lot of books data. Now the idea is that I will pick this JSON data and then I will continue on to work and build. An API that we can serve these books to a front end. And then since it's an API, the backend is in Python, we create the backend where we do different data processing.\n",
      "We create the API, which is a layer in between our backend and. Any front end application. You could [00:01:00] use, for example you could use React, you could use Typi, you could use Plotly, you could Plotly Dash, you could use streamlet, et cetera. Or you can use yeah, whatever you want as a front end and just connect to this API.\n",
      "That is the idea. But this is, a very basic one. We'll create a crud application now.\n",
      "Kokchun Giang-1: here I am in Visual Studio Code and~~ besides, ~~besides this data here, it's empty. This is from a previous video where we used the Gemini ~~together with ap ~~together with Edan in order to create structured JSON data. And what we did was the library do Jason. Here you can see ulu Library, and here we get all the books.\n",
      "And the only difference is that from that video is that I added IDs. I've added IDs for each of the books. Otherwise, it's the same data as we've gotten from that video. I will link that in the description as well. Otherwise, this is a completely empty repository or completely [00:02:00] empty folder.\n",
      "And we create a terminal here. We'll create a new virtual environment, UVNV, and then Source Van Beam Activate. We activated it. We have fast API crud. This is, we will create the crud, API. That means create, read, update, and delete. In order to do that we will start with installing. UV PIP installed we will need to have let's see, what do we need?\n",
      "We need to have fast API, of course, UV corn to run fast. API. And we need we can start with this one. And if we need something else, we'll install it on the way. Okay, then let's start with creating our A-P-I-A-P dot pi. And here from fast API import fast, API we will also do like this. We will create a.\n",
      "Constance Stance pi, and inside of the [00:03:00] Constance Pi, I need to have the data path. From path lib, import path, remember, we're in normal Python script, and in order to define a path here, we will need to have path lib. Then data path. Data path equals to path of d the file. It's this is path to this constant PI and then dot parent.\n",
      "And then you can, you are in fast, API crud. You can see all of these folders. And I will go into the data folder. Then this data path exists here we can import it in in elsewhere. And also let's see. We will need to have I will need to have another script here. I'll create another script called DataCore Processing pi.\n",
      "The reason for doing this is that I don't want to put everything into my API module. I want to separate it and and make it more [00:04:00] scalable. We will start with reading in the data. Import j we will take from Constance import data path and then we will do def read Jason, and here I'll place in the fine name and with open data path slash fine name.\n",
      "And I want to ~~read it. ~~Read it. We take R as file, and then data equal to js dot load file. And then we return data basically like that. We can try this out. If d the name equals to D the main, then we'll do read Jason. And what do we want to place in? What is this called? It's called Library [00:05:00] Jason.\n",
      "Library J data goes to this, and then I will print the data and I'll run this one. Okay. You can see we have the data here. If we want to print a little bit nicely, we can do from P print, import P print. And then instead of print, I will do p print instead. Clear the terminal and run it again. Okay.\n",
      "Yeah, it still looked, oh. I had print here. P print. Oh yeah. Now it looks better. You can see books. We have. Name also. But in inside of books we have a list of dictionaries. It's a list of dictionaries. Since it's a list of dictionary, we can do it like this. We can create a class called book.\n",
      "This is our model, our book model. And what we need is from P den [00:06:00] import base model. Base model, comma field. And this book, I will call base model. It's it's inheriting base model. It means that this one will become a a edan model, but it's still a normal class. It's a class, but it's a Edan model as well.\n",
      "Id in. You can see inside of books here, it's for each book you can see we have id, we have author, title, and year. Okay. And then we can have title, it's a string. We can have author. It's a string as well. And we have a year. It's an int and this is a field. I want it to be greater than equals to greater than 1000 and less than equals to this year.\n",
      "\n",
      "And to get this year, we can do current year plus one. And [00:07:00] to get the current year let me just go into Constance and we can do from daytime import daytime, and we can do. Current year equals to date time now year. It means that data processing, we can import that from stance import current year.\n",
      "\n",
      "And what this means is that~~ we have a. We, ~~we want it to be larger than, greater than 1000. And we want it to be less than 2026, since it's 2025 now. This current year will become 2025 and plus one, we'll have 2026. Okay? This is our gigantic model and ~~for ~~for our book. ~~And then we can do, also, we can do.~~\n",
      "Class library. It's a base model and the name is String and [00:08:00] Books is list of book, we have this book here that is a model. Library is having the name and it has several books. If you're not familiar with pedantic, make sure to take a look into my pedantic videos ~~before ~~because~~ they will, ~~they are the foundation for fast API fast.\n",
      "API uses pedantic a lot for validating the data. Then we have. Library here, and we can also do like this. We can do deaf library data or file name and then Jason. Jason. Data equals to read Jason. I use the read Jason by placing the fine name and then return library. ~~Model validate ~~model, validate JSON data.\n",
      "Okay, this means that [00:09:00] the library will ~~we, ~~we can do library data. It will read this ~~Jason ~~file. And get this JSON data. And then we'll do library do model validate. This means that instead of doing ~~re ~~json like this, we can try this out by doing library equals to library data of let's see, what's it called?\n",
      "Library J.\n",
      "And we can take a look into library. What does that look like? If I run this one, you can see it's a library object where we have the name Ulu Library, we have books. And we have all the books here. And each of the books contain a book object or a book instance where we have ID title, we have author and year.\n",
      "These [00:10:00] are all ~~edan ~~models. All the book are the models. Library is a pedantic model. That means that we have already validated the data that it comes into the ~~right ~~right fields. We have in string and we have interior with the correct fields here. If you, for example, take a look, for example, if we take 19 ~~hundreds ~~here, we'll have a fail here because you can see there's a lot of books here.\n",
      "Books one year. You can see input should be greater than 1900 books. Five point year input should be greater than 1900, et cetera. And here you can see it's 18 13, 18 51. You can see there is, it's validating the data, but ~~the ~~I want to make it simple. I just take 1000 here. If I run this one, it should be fine because all have years greater than 1000.\n",
      "Okay, for this I'm quite satisfied with the data processing. Let's move on to our API. Inside of the API dot [00:11:00] pi, you start with creating an app equals to fast API. ~~This ~~now we have a fast API application, and then. What we should do also is that we'll read in the data. I can do it before actually library equals to, from data processing, import library data, and we can do library data here.\n",
      "~~Library J. ~~Then we have the library, and then we can get the books. And if you see library to get the books, we do library, do books, library dot books. And basically now you can p print the, ~~let's see, ~~we need to import P print from P print, import, P print. And we can do p print of books. If I just run this one, you can see here are all the books and it's a list of the books.\n",
      "~~Good. ~~And we can now we have our Fast API application and we can create our [00:12:00] first endpoint. At app get. If I go into my URL and I do ~~slash. My first endpoint ~~slash books, I should read all the books, this is a decorator, it'll decorate a function that makes it into ~~a a end ~~an endpoint with the GET request.\n",
      "Get is~~ sim, it's ~~the read operation in crud. Create, read, update, delete. ~~We'll create, ~~this is a get request, then you do async dev and async is to make the the function asynchronous that it doesn't get stuck when when running this one. But fast. API actually makes all the endpoints into async by default, but I type it out to make it extra clear.\n",
      "Async dev read books. Return books basically. Let's try out this endpoint. To try it out, you do like this. You have activated your virtual environment. You have installed UV, corn and [00:13:00] fast API. Let's do UV corn api, pi API Colon app. ~~API is this API. ~~You don't~~ in ~~include the dot pi and then you take what the fast API application's name, which is app, and then that dash reload.\n",
      "You don't need to run it each time you change the code. I run this one and what we get is a server that runs on ~~8,000, ~~port 8,000. ~~I run this one. ~~I will have this side by side. I will make this a little bit bigger and this a little bit smaller like this.\n",
      "Actually, I will have this run out like this. Okay? Right now it says detail not found, but if you do slash books, you can see, ah, these are our books. Wow. Cool. Okay, we can click indented write out the indented code.\n",
      "Kokchun Giang-2: Yes. Much cooler. Now it's indented. You can read the data very clearly. Okay, what is the point with [00:14:00] this? When you have it you serve it in API like this. You have a URL, and you can use this URL to do, get request. For example~~ if you ~~if you are in a Jupyter Notebook and you do request on this data.\n",
      "~~You will get this data back. You do request on this URL, ~~you will get this data back and that means that you can serve this to ~~a ~~a frontend application without problems. Let's show you. Another very neat thing is in fast API, there is something called Swagger ui. You go into slash docs and you come into this documentation page here in Fast, API, and you can see there's this get request here.\n",
      "You can click here and you can try it out and you can execute it. And what you can see here is that to do curl. You do type like this and curl is basically what you type in your terminal. If I create a new terminal here and I paste this in this curl, and you can see I get the data. Cool. [00:15:00] And you can, this is the request, URL.\n",
      "As you saw before, we have this URL and then stash books. Then ~~we get into this ~~we get the data we can copy this one and you can see we open here. And you can see we get the data good. And then the response, you can get it here. When you have Swagger ui, you can directly interact with your API through this user interface.\n",
      "And this is really neat. You don't need to have a third party tool such as Postman or some other ~~to ~~tools. You can do it directly here. Okay? Let us continue building on our API. We'll create something called a path parameter. And the path parameter, you should place it before your query parameters.\n",
      "I'll show you what ~~per ~~query parameters is also. App get slash books. We still go into [00:16:00] slash books and then we go into title. And we go into, we type in the title. This is how you do path Parameter. You have curly braces of ~~your your what you want to ~~what the variable should be, what the string should be after the slash title.\n",
      "This one will go into Async f Read book by title. And then you will take the title, it's a string and we should return book for book in books. If book do, title do case fold. Case fold, makes it lowercase equals two. Title case fold. It's lowercase.\n",
      "Let me make it a little bit bigger. What it does is that we have book ~~four ~~[00:17:00] book in books. We get all the books by this title. Where the book, ~~the ~~title equals to. Title case fold. It means that we can type in books with capital letters and it doesn't matter, it will be translated.\n",
      "Let's restart this one. You can see, oh, we get another get request there. Try this out and you can see in Swagger ui you can just type in the title. What title do we have? The Great Gatsby. The great Gaby. Let me just type it like this and show that it works. Anyway, execute, and you can see we get back this de Great Gatsby f Scott Fitzgerald.\n",
      "Okay, here you can see this is the URL there. And then we have percentage, 20, great percentage, 20 Gatsby. Percentage, 20 means [00:18:00] space. This is the URL. If you copy this URL and you go into here, you can see we get this data back. It works. Okay, let's continue. This was a path parameter. You could do ~~per ~~parameters or IDs also if you want.\n",
      "Now let's do a ~~query parameter. ~~Query parameter. It'll, it means that you have a question mark after your endpoint. Start on this, ~~or year ~~I will use this one equals 1950, for example, if you do this. Then this variable start year equals 1950 will be used in our endpoint. At app get slash books slash this one here, we'll go into the books and put in our question mark.\n",
      "Let's [00:19:00] see, async dev filter books ~~and. ~~And what I want to do is start here. This is an int equals to let me import. ~~Query. Query. It's for query, pars ~~query. For default value. This is similar to using the field~~ in in, ~~in pedantic. Query, I want it to be by default, 1950 greater equals to say 1500 less than equals to Let's take current year.\n",
      "From Constance import current year, this equals current year plus one.\n",
      "And then I will also have a description,\n",
      "~~the script, ~~the description equals [00:20:00] to filters, books that are newer than this year. ~~Okay. ~~Okay. Let's see. This is my ~~deaf ~~and I will do filtered books equals to book for book in books. If start year is less than book ~~thought ~~year. Basically like this. Okay, I filter these books and what we do is that we want to return filtered books.\n",
      "Okay? Save this one. Go into swagger, ui, update it. And you can see here we have filter books. I test this out. Okay, try 1950, execute. And you saw that. Okay. We don't get [00:21:00] any books back. Let's see why. Book for book in books. If start year is less than book that year book that year and start year is an int.\n",
      "Oh, I haven't, oh. I have run it. It's, it is run. Okay. I saved this one.\n",
      "Try it out. Filter books that are new than this year. 1950. Execute. I get back nothing. Let me see why. Less than greater than 1500. Less than. 2051. 2026. Filter. This book? Yeah. Oh, okay. Filter book. Ah, filter books. Yeah. I return this function. Of course it doesn't give anything. [00:22:00] Okay. Execute this one and it works.\n",
      "And you can see all of them are newer than 1950. If I take, for example, 90 55 here. We will not get a lot of the rings. If I run this one, we'll only get these two. Okay, great. It works. Now we filter by this, but if you want, you can also, we can see this is the URL, you have slash books, and then we have question marks.\n",
      "Start year equals 90 55. If we want, we can put in more parameters to to query parameters we can have author also if we want. Author is a string. It's a query. None you don't play. It makes it optional. And then we can have a description authors first name and last name. Filter by author's, first name and last name.[00:23:00] \n",
      "Okay, this is the description and we have author and then we can filter the book. If author, it means it's not none, then filtered books equals to this list. Book for book in filtered books. If author.case fold. Equals to book author case fold. Then we return these books here, save this one or update this one.\n",
      "You can see now author comes in as well. Try it out and you can see if we just take 1950 and execute it, it works. ~~Because we haven't ~~because this is it has none as the fault, it's optional. But if I put in an author, for example, Douglas Adams. Douglas Adams [00:24:00] execute it, you can see we get only this one back.\n",
      "Good. This one works. Now we only use the get requests. We are still in read. If we want to create a crud operations, we should do create as well. To do create, we do app post. What you want to do is ~~you want to put in a, ~~you want to post a new book. Books slash create book. And here, async Deaf, great book request.\n",
      "You want to put in a new book as a J object, and this should be book.\n",
      "Okay, and ~~we don't have books, ~~we need to import this one import book. This is the Edan model. It means that it has to conform to the, to, to the fields in the Edan model in order for it to create a new book and then [00:25:00] to create a new book. It's as simple as this new book equals to book model.\n",
      "A ~~book is a, remember the ~~book is a pedantic model, we can ~~do model ~~validate our book request. Just to make sure we turn it into ~~a. ~~A book object. And then what we do is books that append new book. And remember that we append the book. We have our books ~~contains a lot of they ~~contains book objects that are pedantic models.\n",
      "However, when we serve it in the API remember that it gives us ~~chase in ~~data. And what it does is that fast API automatically. ~~It ~~converts it ~~into ~~into JSON data, and that is very good. We have return new book because this is good to do. ~~When you ~~when you basically, you have appended it into your books.\n",
      "That when you do [00:26:00] get request, you will see the new book as well. However when you do post you want to return a new book to show you that it's the new book that is placed in. Let's update this one, and now you can see there's a post. Go into here. We try this out and these are example values you can see.\n",
      "Id zero now. We haven't done ~~any ~~any validation on the id. You could do that. ~~14, ~~for example, title is a string. ~~And what is this? ~~This example is based on our P model. You can see our book model here. It's an int that's why they have a value here, a string. It's also an author.\n",
      "It's also string. You got the value as strings here and int you get this field. Here. ~~Let us make this let us just try or ~~let us make this more helpful. In the documentation. To do that, we go into our data processing and into our book model, [00:27:00] and we'll do something called model config.\n",
      "It's a dictionary, Jason Schema Extra. This is another dictionary. And here we have an example and. Which is non dictionary. And now the example, let's take ID colon 11. We have a title right then with a engineer,\n",
      "author co yang here. 2025. Save this one\n",
      "and let us try it out now. If I update this one, you can see, ah, this is the example values. Good. Try it out. And you can see this example values. Yeah, [00:28:00] we can use this directly. Execute, and you can see that. The response body, it gives back this one. This is the response after we have posted it. Okay.\n",
      "But let's see if this book is there. Read books, try it out, execute. You can see down here. Ah, 11. Learn with Engineer K Young. Okay, cool. Our post request works. And also you can try it out here if you want to read all books.\n",
      "You can see that. Yeah, it's here. Now we have posted the data and let us continue now. We have. Create is post in in fast, API and we can do at app update. This is the update and we can slash books [00:29:00] slash up update book, async dev update book. Updated book. It's a book object, a book model for I book in enumerate books.\n",
      "This means that we'll get indexes for each of the books. And then if book ID equals to Id.\n",
      "Let's see if book ID equals ~~updated book id, ~~updated book id. If this is the case, then books of I equals the updated book. ~~Okay, it means that. We will update ~~we will create~~ when we update we put in ~~a JSON object and the JS ~~O ~~will [00:30:00] take a look into the id. If it's the same ID as another book that exists, then we'll update that book.\n",
      "Otherwise, we won't do anything. After that, we return our updated book. ~~Okay. ~~Fast. API don't let's see. Oh it's not called update. It's called put in fast. API ~~it's called Put. ~~Okay, let us try to change ID 10 here. In my, put, try it out. Let's change Id 10 to. Okay, cool Book. And I've written it, execute it and it returns back this updated book.\n",
      "Let's look into here. This is my slash books here. If I run this one, you can see, ah, I did 10. [00:31:00] Cool book. And why did my 11 disappear? Yeah, because I have reloaded it. Then the data is not stored in the j per se, we haven't done logic for that in, instead it's just for this run here.\n",
      "If you want it to be stored, you should connect it to a database, but I won't show it here. We have done update book. What is left is that we need to delete book. Then we have our cred application. App delete slash books slash delete book slash id. This is a what's called, it's a, puff parameter, async deaf delete book, and it should take in the ID [00:32:00] as an ink and for I comma book in enumerate books. If book id. Equals id. Then we delete this book, books of I Break. Okay, let's try this out. ~~Update this one. ~~Delete id. Let's remove one. Execute.\n",
      "If we go back here and take a look into all the books. You can see ID one has disappeared. Let's remove ID five as well. Five execute. And now we need to rerun this one. Execute. And you can see five has disappeared. Cool. This is our fast API application\n",
      "Kokchun Giang-3: We have created our [00:33:00] first CRUD application ~~using ~~using Fast API. ~~And ~~here we have worked with ~~p we have worked with Jason ~~Data and we have created our. ~~Book API ~~books API, that you can read from the books get requests, you can do posts, you can do update, you can do update by put, and you can do deletes.\n",
      "This is ~~really ~~really interesting ~~and ~~and what you can do later with this is that you can connect this into a frontend application. ~~And ~~and then you can, mix and match and use whatever ~~frontend application you want. ~~Frontend framework. You want ~~to do this that ~~if you want to mix Python with JavaScript, no problems.\n",
      "If you want to mix Python with something else, that's no problem either. You can use Python all the way. ~~Also, ~~that's also possible. There's a lot of opportunities when you work with APIs. It's a layer in between now and this is really interesting and I hope. ~~Hope that ~~you have learned a lot from this video ~~and ~~thank you.\n",
      "See you in the next one. Bye.\n"
     ]
    }
   ],
   "source": [
    "md_file = next(DATA_PATH.glob(\"*.md\"))\n",
    "text = convert_md_txt(md_file)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4ef25",
   "metadata": {},
   "source": [
    "### Exploring txt-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff0756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/t8g0_t_n1_9bcmhw9_c95wnc0000gn/T/ipykernel_25935/3036452005.py:4: DeprecationWarning: table_names() is deprecated, use list_tables() instead\n",
      "  vector_db.table_names()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['YouTube']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "\n",
    "vector_db = lancedb.connect(uri = \"knowledge_base\")\n",
    "vector_db.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f2b8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanceTable(name='youtube', version=108, _conn=LanceDBConnection(uri='/Users/efrem_27/Documents/github/AI_engineer_project/knowledge_base'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db[\"youtube\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c34d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>filepath</th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an introduction to the vector database lancedb</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>an introduction to the vector database lancedb</td>\n",
       "      <td>An introduction to the vector database LanceDB...</td>\n",
       "      <td>[-0.038165595, 0.005839912, 0.02174149, -0.073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data platform course structure</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>data platform course structure</td>\n",
       "      <td>Data platform course structure\\n[00:00:00] Hel...</td>\n",
       "      <td>[0.010596283, 0.0007604208, 0.011798323, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>SQL analytics course with DuckDB - Sakila BI d...</td>\n",
       "      <td>[0.003561765, -0.0024968137, 0.018408697, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic regression theory</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>logistic regression theory</td>\n",
       "      <td>Logistic regression theory\\n[00:00:00] Hello a...</td>\n",
       "      <td>[-0.00641446, 0.0017129751, 0.0117463, -0.0701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data processing course  structure</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>data processing course  structure</td>\n",
       "      <td>data processing course structure\\nKokchun: [00...</td>\n",
       "      <td>[0.0030052175, 0.012903026, 0.0074207284, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>SQL analytics course with DuckDB - pandas and ...</td>\n",
       "      <td>[-0.011264389, -0.009431089, 0.013158852, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>python fundamentals</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>python fundamentals</td>\n",
       "      <td>Python fundamentals\\n[00:00:00] Hello and welc...</td>\n",
       "      <td>[-0.010547567, 0.0052952566, 0.015170559, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pytest unit testing</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pytest unit testing</td>\n",
       "      <td>pytest unit testing\\n[00:00:00] Hello and welc...</td>\n",
       "      <td>[-0.013908745, 0.0010215672, 0.029968578, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pydantic with gemini to structure output in a ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pydantic with gemini to structure output in a ...</td>\n",
       "      <td>Pydantic with gemini to structure output in a ...</td>\n",
       "      <td>[-0.015264044, -0.0024070442, 0.015796792, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logistic regression hands on with scikit learn</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>logistic regression hands on with scikit learn</td>\n",
       "      <td>Logistic regression hands on with scikit learn...</td>\n",
       "      <td>[-0.0069891424, 0.0071438453, 0.012519629, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sql analytics course with duckdb - crud operat...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - crud operat...</td>\n",
       "      <td>SQL analytics course with DuckDB - CRUD operat...</td>\n",
       "      <td>[-0.018761043, 0.002032702, 0.02506354, -0.063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>python_oop_1</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>python_oop_1</td>\n",
       "      <td>Python_oop_1\\nkokchun: [00:00:00] Hello and we...</td>\n",
       "      <td>[-0.007964168, -0.010724814, 0.03142313, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sql analytics course with duckdb - setup duckdb</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - setup duckdb</td>\n",
       "      <td>SQL analytics course with DuckDB - setup duckd...</td>\n",
       "      <td>[-0.007941736, -0.0017214945, 0.017682433, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hands on regularization</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>hands on regularization</td>\n",
       "      <td>Hands on regularization\\n[00:00:00] Hello and ...</td>\n",
       "      <td>[-0.008896271, 0.001761678, 0.023786722, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>course structure for azure two weeks course</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>course structure for azure two weeks course</td>\n",
       "      <td>Course structure for Azure two weeks course\\n[...</td>\n",
       "      <td>[0.0031295605, 0.014166776, 0.016287401, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>SQL analytics course with DuckDB - Sakila BI d...</td>\n",
       "      <td>[0.003561765, -0.0024968137, 0.018408697, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>SQL analytics course with DuckDB - set theory ...</td>\n",
       "      <td>[-0.028066158, -0.019780347, 0.019481514, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pydanticai chatbot</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pydanticai chatbot</td>\n",
       "      <td>pydanticAI chatbot\\n[00:00:00] Hello and welco...</td>\n",
       "      <td>[-0.011707014, -0.0005243588, 0.013498923, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chat with your excel data - xlwings lite (1)</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>chat with your excel data - xlwings lite (1)</td>\n",
       "      <td>Chat with your excel data - xlwings lite\\nKokc...</td>\n",
       "      <td>[-0.0073488248, 0.021756327, 0.016487604, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>modern data stack - using dlt to extract and l...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>modern data stack - using dlt to extract and l...</td>\n",
       "      <td>Modern data stack - using dlt to extract and l...</td>\n",
       "      <td>[-0.009853688, 0.02026993, 0.0176039, -0.08109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data storytelling</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>data storytelling</td>\n",
       "      <td>data storytelling\\n[00:00:00] Hello and welcom...</td>\n",
       "      <td>[-0.009587259, 0.017984493, 0.012533942, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>api trafiklab (1)</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>api trafiklab (1)</td>\n",
       "      <td>API trafiklab\\n[00:00:00] Hello and welcome to...</td>\n",
       "      <td>[-0.004888756, -0.0044691996, 0.014377842, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fastapi crud app</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>fastapi crud app</td>\n",
       "      <td>Fastapi CRUD app\\nKokchun Giang: [00:00:00] He...</td>\n",
       "      <td>[-0.010539368, -0.015074633, 0.022835571, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>api trafiklab</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>api trafiklab</td>\n",
       "      <td>API trafiklab\\n[00:00:00] Hello and welcome to...</td>\n",
       "      <td>[-0.004888756, -0.0044691996, 0.014377842, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sql analytics course with duckdb - joins concepts</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - joins concepts</td>\n",
       "      <td>SQL analytics course with DuckDB - joins conce...</td>\n",
       "      <td>[-0.027226884, -0.016104657, 0.011940904, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fastapi and scikit-learn api connect to stream...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>fastapi and scikit-learn api connect to stream...</td>\n",
       "      <td>FastAPI and scikit-learn API connect to stream...</td>\n",
       "      <td>[-0.016197618, 0.01243914, 0.018560743, -0.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>Serving PydanticAI Gemini Model with FastAPI T...</td>\n",
       "      <td>[-0.017158316, -0.005054007, 0.016186513, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>packaging in python</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>packaging in python</td>\n",
       "      <td>Packaging in python\\n[00:00:00] Hello and welc...</td>\n",
       "      <td>[-0.015012743, 0.005314837, 0.037370495, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>modern data stack - deploy dockerized dashboar...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>modern data stack - deploy dockerized dashboar...</td>\n",
       "      <td>Modern data stack - deploy dockerized dashboar...</td>\n",
       "      <td>[-0.00852369, 0.022943845, 0.027582156, -0.104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>postgres sink</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>postgres sink</td>\n",
       "      <td>postgres sink\\n[00:00:00] Hello and welcome to...</td>\n",
       "      <td>[0.008457462, 0.02178748, 0.032398567, -0.0877...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sql analytics course with duckdb - views tutorial</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - views tutorial</td>\n",
       "      <td>SQL analytics course with DuckDB - views tutor...</td>\n",
       "      <td>[-0.026221767, -0.0056624073, 0.0042914175, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>python intro</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>python intro</td>\n",
       "      <td>python intro\\n[00:00:00] Hello and welcome to ...</td>\n",
       "      <td>[-0.010726931, -0.0021426522, 0.012746945, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>chat with your excel data - xlwings lite</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>chat with your excel data - xlwings lite</td>\n",
       "      <td>Chat with your excel data - xlwings lite\\nKokc...</td>\n",
       "      <td>[-0.0073488248, 0.021756327, 0.016487604, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>docker setup windows</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>docker setup windows</td>\n",
       "      <td>docker setup windows\\n[00:00:00] Hello and wel...</td>\n",
       "      <td>[-0.002607342, 0.011477059, 0.017320504, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sql analytics with duckdb - introduction</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics with duckdb - introduction</td>\n",
       "      <td>SQL analytics with DuckDB - introduction\\n[00:...</td>\n",
       "      <td>[-0.027429162, -0.010124963, 0.006358245, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sql analytics course with duckdb - course stru...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - course stru...</td>\n",
       "      <td>SQL analytics course with DuckDB - course stru...</td>\n",
       "      <td>[0.0023808868, -0.0016924503, 0.0038941107, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>azure static web app deploy react app</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>azure static web app deploy react app</td>\n",
       "      <td>Azure static web app deploy react app\\n[00:00:...</td>\n",
       "      <td>[-0.013259199, 0.017627934, 0.025625126, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>how does llm work_</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>how does llm work_</td>\n",
       "      <td>How does LLM work?\\n[00:00:00] Hello and welco...</td>\n",
       "      <td>[-0.026513925, 0.018813677, 0.023627453, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>terraform setup</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>terraform setup</td>\n",
       "      <td>Terraform setup\\n[00:00:00] Hello and welcome ...</td>\n",
       "      <td>[-0.0044360664, 0.021062179, 0.016942821, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>pandas_read_excel</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pandas_read_excel</td>\n",
       "      <td>pandas_read_excel\\n[00:00:00] Hello and welcom...</td>\n",
       "      <td>[-0.004386253, 0.006513567, 0.024039451, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pydantic fundamentals</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pydantic fundamentals</td>\n",
       "      <td>Pydantic fundamentals\\n[00:00:00] Hello and we...</td>\n",
       "      <td>[-0.01768868, -0.0106104445, 0.021348534, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sql analytics course with duckdb - joins with ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - joins with ...</td>\n",
       "      <td>SQL analytics course with DuckDB - joins with ...</td>\n",
       "      <td>[-0.023188569, -0.020161223, 0.012935176, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pydanticai fundamentals - outputting structure...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pydanticai fundamentals - outputting structure...</td>\n",
       "      <td>PydanticAI fundamentals - outputting structure...</td>\n",
       "      <td>[-0.03427028, 0.003974868, 0.025365941, -0.076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sql analytics course with duckdb - strings con...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - strings con...</td>\n",
       "      <td>SQL analytics course with DuckDB - strings con...</td>\n",
       "      <td>[-0.025746755, -0.00897205, 0.0034949258, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>SQL analytics course with DuckDB - pandas and ...</td>\n",
       "      <td>[-0.011264389, -0.009431089, 0.013158852, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>SQL analytics course with DuckDB - set theory ...</td>\n",
       "      <td>[-0.028066158, -0.019780347, 0.019481514, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>sql analytics course with duckdb - subquery tu...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - subquery tu...</td>\n",
       "      <td>SQL analytics course with DuckDB - subquery tu...</td>\n",
       "      <td>[-0.01246018, -0.012045197, -0.0021293734, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sql analytics course with duckdb - strings tut...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - strings tut...</td>\n",
       "      <td>SQL analytics course with DuckDB - strings tut...</td>\n",
       "      <td>[-0.021604763, -0.0006556192, 0.009578983, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>dbt modeling snowflake</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>dbt modeling snowflake</td>\n",
       "      <td>dbt modeling snowflake\\nKokchun Giang: [00:00:...</td>\n",
       "      <td>[-0.011131446, 0.013321222, 0.028704425, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>Serving PydanticAI Gemini Model with FastAPI T...</td>\n",
       "      <td>[-0.017158316, -0.005054007, 0.016186513, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sql analytics course with duckdb - dlt to load...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - dlt to load...</td>\n",
       "      <td>SQL analytics course with DuckDB - dlt to load...</td>\n",
       "      <td>[-0.008279277, -0.0047078263, 0.01916089, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>modern data stack - dockerize your data pipeline</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>modern data stack - dockerize your data pipeline</td>\n",
       "      <td>Modern data stack - dockerize your data pipeli...</td>\n",
       "      <td>[0.0016710534, 0.015011349, 0.026834052, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>xgboost hands on tutorial for classification</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>xgboost hands on tutorial for classification</td>\n",
       "      <td>XGBoost hands on tutorial for classification\\n...</td>\n",
       "      <td>[-0.0050945953, 0.010234255, 0.013902015, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               doc_id  \\\n",
       "0      an introduction to the vector database lancedb   \n",
       "1                      data platform course structure   \n",
       "2   sql analytics course with duckdb - sakila bi d...   \n",
       "3                          logistic regression theory   \n",
       "4                   data processing course  structure   \n",
       "5   sql analytics course with duckdb - pandas and ...   \n",
       "6                                 python fundamentals   \n",
       "7                                 pytest unit testing   \n",
       "8   pydantic with gemini to structure output in a ...   \n",
       "9      logistic regression hands on with scikit learn   \n",
       "10  sql analytics course with duckdb - crud operat...   \n",
       "11                                       python_oop_1   \n",
       "12    sql analytics course with duckdb - setup duckdb   \n",
       "13                            hands on regularization   \n",
       "14        course structure for azure two weeks course   \n",
       "15  sql analytics course with duckdb - sakila bi d...   \n",
       "16  sql analytics course with duckdb - set theory ...   \n",
       "17                                 pydanticai chatbot   \n",
       "18       chat with your excel data - xlwings lite (1)   \n",
       "19  modern data stack - using dlt to extract and l...   \n",
       "20                                  data storytelling   \n",
       "21                                  api trafiklab (1)   \n",
       "22                                   fastapi crud app   \n",
       "23                                      api trafiklab   \n",
       "24  sql analytics course with duckdb - joins concepts   \n",
       "25  fastapi and scikit-learn api connect to stream...   \n",
       "26  serving pydanticai gemini model with fastapi t...   \n",
       "27                                packaging in python   \n",
       "28  modern data stack - deploy dockerized dashboar...   \n",
       "29                                      postgres sink   \n",
       "30  sql analytics course with duckdb - views tutorial   \n",
       "31                                       python intro   \n",
       "32           chat with your excel data - xlwings lite   \n",
       "33                               docker setup windows   \n",
       "34           sql analytics with duckdb - introduction   \n",
       "35  sql analytics course with duckdb - course stru...   \n",
       "36              azure static web app deploy react app   \n",
       "37                                 how does llm work_   \n",
       "38                                    terraform setup   \n",
       "39                                  pandas_read_excel   \n",
       "40                              pydantic fundamentals   \n",
       "41  sql analytics course with duckdb - joins with ...   \n",
       "42  pydanticai fundamentals - outputting structure...   \n",
       "43  sql analytics course with duckdb - strings con...   \n",
       "44  sql analytics course with duckdb - pandas and ...   \n",
       "45  sql analytics course with duckdb - set theory ...   \n",
       "46  sql analytics course with duckdb - subquery tu...   \n",
       "47  sql analytics course with duckdb - strings tut...   \n",
       "48                             dbt modeling snowflake   \n",
       "49  serving pydanticai gemini model with fastapi t...   \n",
       "50  sql analytics course with duckdb - dlt to load...   \n",
       "51   modern data stack - dockerize your data pipeline   \n",
       "52       xgboost hands on tutorial for classification   \n",
       "\n",
       "                                             filepath  \\\n",
       "0   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "1   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "2   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "3   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "4   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "5   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "6   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "7   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "8   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "9   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "10  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "11  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "12  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "13  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "14  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "15  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "16  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "17  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "18  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "19  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "20  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "21  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "22  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "23  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "24  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "25  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "26  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "27  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "28  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "29  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "30  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "31  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "32  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "33  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "34  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "35  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "36  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "37  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "38  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "39  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "40  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "41  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "42  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "43  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "44  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "45  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "46  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "47  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "48  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "49  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "50  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "51  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "52  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "\n",
       "                                             filename  \\\n",
       "0      an introduction to the vector database lancedb   \n",
       "1                      data platform course structure   \n",
       "2   sql analytics course with duckdb - sakila bi d...   \n",
       "3                          logistic regression theory   \n",
       "4                   data processing course  structure   \n",
       "5   sql analytics course with duckdb - pandas and ...   \n",
       "6                                 python fundamentals   \n",
       "7                                 pytest unit testing   \n",
       "8   pydantic with gemini to structure output in a ...   \n",
       "9      logistic regression hands on with scikit learn   \n",
       "10  sql analytics course with duckdb - crud operat...   \n",
       "11                                       python_oop_1   \n",
       "12    sql analytics course with duckdb - setup duckdb   \n",
       "13                            hands on regularization   \n",
       "14        course structure for azure two weeks course   \n",
       "15  sql analytics course with duckdb - sakila bi d...   \n",
       "16  sql analytics course with duckdb - set theory ...   \n",
       "17                                 pydanticai chatbot   \n",
       "18       chat with your excel data - xlwings lite (1)   \n",
       "19  modern data stack - using dlt to extract and l...   \n",
       "20                                  data storytelling   \n",
       "21                                  api trafiklab (1)   \n",
       "22                                   fastapi crud app   \n",
       "23                                      api trafiklab   \n",
       "24  sql analytics course with duckdb - joins concepts   \n",
       "25  fastapi and scikit-learn api connect to stream...   \n",
       "26  serving pydanticai gemini model with fastapi t...   \n",
       "27                                packaging in python   \n",
       "28  modern data stack - deploy dockerized dashboar...   \n",
       "29                                      postgres sink   \n",
       "30  sql analytics course with duckdb - views tutorial   \n",
       "31                                       python intro   \n",
       "32           chat with your excel data - xlwings lite   \n",
       "33                               docker setup windows   \n",
       "34           sql analytics with duckdb - introduction   \n",
       "35  sql analytics course with duckdb - course stru...   \n",
       "36              azure static web app deploy react app   \n",
       "37                                 how does llm work_   \n",
       "38                                    terraform setup   \n",
       "39                                  pandas_read_excel   \n",
       "40                              pydantic fundamentals   \n",
       "41  sql analytics course with duckdb - joins with ...   \n",
       "42  pydanticai fundamentals - outputting structure...   \n",
       "43  sql analytics course with duckdb - strings con...   \n",
       "44  sql analytics course with duckdb - pandas and ...   \n",
       "45  sql analytics course with duckdb - set theory ...   \n",
       "46  sql analytics course with duckdb - subquery tu...   \n",
       "47  sql analytics course with duckdb - strings tut...   \n",
       "48                             dbt modeling snowflake   \n",
       "49  serving pydanticai gemini model with fastapi t...   \n",
       "50  sql analytics course with duckdb - dlt to load...   \n",
       "51   modern data stack - dockerize your data pipeline   \n",
       "52       xgboost hands on tutorial for classification   \n",
       "\n",
       "                                              content  \\\n",
       "0   An introduction to the vector database LanceDB...   \n",
       "1   Data platform course structure\\n[00:00:00] Hel...   \n",
       "2   SQL analytics course with DuckDB - Sakila BI d...   \n",
       "3   Logistic regression theory\\n[00:00:00] Hello a...   \n",
       "4   data processing course structure\\nKokchun: [00...   \n",
       "5   SQL analytics course with DuckDB - pandas and ...   \n",
       "6   Python fundamentals\\n[00:00:00] Hello and welc...   \n",
       "7   pytest unit testing\\n[00:00:00] Hello and welc...   \n",
       "8   Pydantic with gemini to structure output in a ...   \n",
       "9   Logistic regression hands on with scikit learn...   \n",
       "10  SQL analytics course with DuckDB - CRUD operat...   \n",
       "11  Python_oop_1\\nkokchun: [00:00:00] Hello and we...   \n",
       "12  SQL analytics course with DuckDB - setup duckd...   \n",
       "13  Hands on regularization\\n[00:00:00] Hello and ...   \n",
       "14  Course structure for Azure two weeks course\\n[...   \n",
       "15  SQL analytics course with DuckDB - Sakila BI d...   \n",
       "16  SQL analytics course with DuckDB - set theory ...   \n",
       "17  pydanticAI chatbot\\n[00:00:00] Hello and welco...   \n",
       "18  Chat with your excel data - xlwings lite\\nKokc...   \n",
       "19  Modern data stack - using dlt to extract and l...   \n",
       "20  data storytelling\\n[00:00:00] Hello and welcom...   \n",
       "21  API trafiklab\\n[00:00:00] Hello and welcome to...   \n",
       "22  Fastapi CRUD app\\nKokchun Giang: [00:00:00] He...   \n",
       "23  API trafiklab\\n[00:00:00] Hello and welcome to...   \n",
       "24  SQL analytics course with DuckDB - joins conce...   \n",
       "25  FastAPI and scikit-learn API connect to stream...   \n",
       "26  Serving PydanticAI Gemini Model with FastAPI T...   \n",
       "27  Packaging in python\\n[00:00:00] Hello and welc...   \n",
       "28  Modern data stack - deploy dockerized dashboar...   \n",
       "29  postgres sink\\n[00:00:00] Hello and welcome to...   \n",
       "30  SQL analytics course with DuckDB - views tutor...   \n",
       "31  python intro\\n[00:00:00] Hello and welcome to ...   \n",
       "32  Chat with your excel data - xlwings lite\\nKokc...   \n",
       "33  docker setup windows\\n[00:00:00] Hello and wel...   \n",
       "34  SQL analytics with DuckDB - introduction\\n[00:...   \n",
       "35  SQL analytics course with DuckDB - course stru...   \n",
       "36  Azure static web app deploy react app\\n[00:00:...   \n",
       "37  How does LLM work?\\n[00:00:00] Hello and welco...   \n",
       "38  Terraform setup\\n[00:00:00] Hello and welcome ...   \n",
       "39  pandas_read_excel\\n[00:00:00] Hello and welcom...   \n",
       "40  Pydantic fundamentals\\n[00:00:00] Hello and we...   \n",
       "41  SQL analytics course with DuckDB - joins with ...   \n",
       "42  PydanticAI fundamentals - outputting structure...   \n",
       "43  SQL analytics course with DuckDB - strings con...   \n",
       "44  SQL analytics course with DuckDB - pandas and ...   \n",
       "45  SQL analytics course with DuckDB - set theory ...   \n",
       "46  SQL analytics course with DuckDB - subquery tu...   \n",
       "47  SQL analytics course with DuckDB - strings tut...   \n",
       "48  dbt modeling snowflake\\nKokchun Giang: [00:00:...   \n",
       "49  Serving PydanticAI Gemini Model with FastAPI T...   \n",
       "50  SQL analytics course with DuckDB - dlt to load...   \n",
       "51  Modern data stack - dockerize your data pipeli...   \n",
       "52  XGBoost hands on tutorial for classification\\n...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.038165595, 0.005839912, 0.02174149, -0.073...  \n",
       "1   [0.010596283, 0.0007604208, 0.011798323, -0.07...  \n",
       "2   [0.003561765, -0.0024968137, 0.018408697, -0.0...  \n",
       "3   [-0.00641446, 0.0017129751, 0.0117463, -0.0701...  \n",
       "4   [0.0030052175, 0.012903026, 0.0074207284, -0.0...  \n",
       "5   [-0.011264389, -0.009431089, 0.013158852, -0.0...  \n",
       "6   [-0.010547567, 0.0052952566, 0.015170559, -0.0...  \n",
       "7   [-0.013908745, 0.0010215672, 0.029968578, -0.0...  \n",
       "8   [-0.015264044, -0.0024070442, 0.015796792, -0....  \n",
       "9   [-0.0069891424, 0.0071438453, 0.012519629, -0....  \n",
       "10  [-0.018761043, 0.002032702, 0.02506354, -0.063...  \n",
       "11  [-0.007964168, -0.010724814, 0.03142313, -0.06...  \n",
       "12  [-0.007941736, -0.0017214945, 0.017682433, -0....  \n",
       "13  [-0.008896271, 0.001761678, 0.023786722, -0.07...  \n",
       "14  [0.0031295605, 0.014166776, 0.016287401, -0.07...  \n",
       "15  [0.003561765, -0.0024968137, 0.018408697, -0.0...  \n",
       "16  [-0.028066158, -0.019780347, 0.019481514, -0.0...  \n",
       "17  [-0.011707014, -0.0005243588, 0.013498923, -0....  \n",
       "18  [-0.0073488248, 0.021756327, 0.016487604, -0.0...  \n",
       "19  [-0.009853688, 0.02026993, 0.0176039, -0.08109...  \n",
       "20  [-0.009587259, 0.017984493, 0.012533942, -0.08...  \n",
       "21  [-0.004888756, -0.0044691996, 0.014377842, -0....  \n",
       "22  [-0.010539368, -0.015074633, 0.022835571, -0.0...  \n",
       "23  [-0.004888756, -0.0044691996, 0.014377842, -0....  \n",
       "24  [-0.027226884, -0.016104657, 0.011940904, -0.0...  \n",
       "25  [-0.016197618, 0.01243914, 0.018560743, -0.085...  \n",
       "26  [-0.017158316, -0.005054007, 0.016186513, -0.0...  \n",
       "27  [-0.015012743, 0.005314837, 0.037370495, -0.07...  \n",
       "28  [-0.00852369, 0.022943845, 0.027582156, -0.104...  \n",
       "29  [0.008457462, 0.02178748, 0.032398567, -0.0877...  \n",
       "30  [-0.026221767, -0.0056624073, 0.0042914175, -0...  \n",
       "31  [-0.010726931, -0.0021426522, 0.012746945, -0....  \n",
       "32  [-0.0073488248, 0.021756327, 0.016487604, -0.0...  \n",
       "33  [-0.002607342, 0.011477059, 0.017320504, -0.07...  \n",
       "34  [-0.027429162, -0.010124963, 0.006358245, -0.0...  \n",
       "35  [0.0023808868, -0.0016924503, 0.0038941107, -0...  \n",
       "36  [-0.013259199, 0.017627934, 0.025625126, -0.09...  \n",
       "37  [-0.026513925, 0.018813677, 0.023627453, -0.06...  \n",
       "38  [-0.0044360664, 0.021062179, 0.016942821, -0.0...  \n",
       "39  [-0.004386253, 0.006513567, 0.024039451, -0.06...  \n",
       "40  [-0.01768868, -0.0106104445, 0.021348534, -0.0...  \n",
       "41  [-0.023188569, -0.020161223, 0.012935176, -0.0...  \n",
       "42  [-0.03427028, 0.003974868, 0.025365941, -0.076...  \n",
       "43  [-0.025746755, -0.00897205, 0.0034949258, -0.0...  \n",
       "44  [-0.011264389, -0.009431089, 0.013158852, -0.0...  \n",
       "45  [-0.028066158, -0.019780347, 0.019481514, -0.0...  \n",
       "46  [-0.01246018, -0.012045197, -0.0021293734, -0....  \n",
       "47  [-0.021604763, -0.0006556192, 0.009578983, -0....  \n",
       "48  [-0.011131446, 0.013321222, 0.028704425, -0.08...  \n",
       "49  [-0.017158316, -0.005054007, 0.016186513, -0.0...  \n",
       "50  [-0.008279277, -0.0047078263, 0.01916089, -0.0...  \n",
       "51  [0.0016710534, 0.015011349, 0.026834052, -0.09...  \n",
       "52  [-0.0050945953, 0.010234255, 0.013902015, -0.0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db[\"youtube\"].to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7e4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efrem_27/Documents/github/AI_engineer_project/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"SQL analytics course with DuckDB - joins concepts\\n[00:00:00] Hello and welcome to this video where we'll go ~~into joins and going ~~into the concepts and intuition about joins that you later on can work with joins in code, which will be the next lecture. And for the coding part, we'll go into starting with some generating synthetic data to do joints to see a very simple case.\\nBut later on we'll move on to the Quila database and do joints over there to see how that looks like. But for this one, it's just a concept. We'll move into the slides directly.\\nKokchun Giang-1: Working with SQL, working with joints in SQL to combine columns from one or more tables. Note that we're talking about columns now except for when we're talking about cross join, which is a special case later on. But now we're talking about the columns here or we're actually talking about the columns in cross joints as well.\\n~~Sorry for that yes. ~~Before we talked about union or set operations and in set operations, we, we talk about rows, [00:01:00] right? Where join we are we're using compound queries. We're using several queries and compounding them together to get the, combining the results set of one with another, with a certain type of set operation.\\nBut for joint operations, we are combining the columns, not the rows. . That is very important. Joints in SQL explain with Venn diagrams here. We use Venn diagrams similar to the set operations. You'll see that they look very similar. Here we have inner join. This corresponds to the intersect for the set operations.\\nBut here we're using it is an intersect of the columns, right? It's the inner join here of column of table A and table B. Here, left join. You use everything that is from the left table table A and then the corresponding columns from the. B from table B there. And for the right joint we [00:02:00] pick the right table.\\nTable B here. And take corresponding rows for the corresponding columns for the table A and for full join, you combine all the columns. From both table A and B. Let's take a look. Here A and B are tables ~~and if, ~~and it's the columns that are joined. Let's take a look into example here.\\nThis is an example. ~~We have, ~~we combine two tables with left join. ~~Here you have a scale code for that. You pick out the, ~~you do from main dot plans. P and left ~~the ~~join with Main Plant Care PC on a certain type of column. ~~We, ~~here, we use Plant ID and we use PC plant id. One from P and one from pc.\\nHere you have plant id ~~here you have planned care. The ID here, actually it's a misspelling. It should be ID here and not plant id. Yes. ~~And then afterwards, when you have done the join you pick out the columns that you want. For example, ~~here, ~~I want plant ID from ~~PI ~~want plant name from ~~PI ~~want P type, right?\\nI want all this from P [00:03:00] and I want PC water schedule, and I want PC sunlight. ? It'll look like this. This is the matching column. You can see. ~~And ~~for P Plant id, this ~~is, you see here ~~is the matching column with this. ~~Or actually it's not the fault I saw. I said that I didn't see a plant ID here, it's actually correct.~~\\n~~We have plant ID here, ~~we have plant ID here. One corresponds to one. Three corresponds to three. Four corresponds to four, right? And then ~~we have five, and ~~we have two and five ~~also, ~~but they don't exist here, right? We will have a plant name and. ~~And the ~~type ~~four, ~~two, and five. But~~ those are not ~~they don't exist in the.\\nIn the right table, like in the planned care, which means that there will be null for water schedule and sunlight. Let's look into that. When we do left joint, and you can see they are null, right? Two and five are null. The other ones are joined according to left joint. It's ~~based on the left tables.~~\\n~~It's the ~~based on the left table, that is left joint. . Returns all records from left table and match with right table giving nulls in right columns if there's no [00:04:00] match. Null means basically it's missing value or not available or yeah, missing or not available. These are notes.\\nAnd here you can see, right? Join. Similarly, we have a matching column you can see here on the matching ones. But we use Right join instead and Right join. It's based on the right column. And that's why these three here become new. Returns all records from right table and match with left table.\\nGiving Nolls in left columns if there's no match. , These are notes and here we have Inner Join. Inner join, you can see we take those that are matching. Only one, three, and four will be matched. The rest are thrown away. That is inner Join. Intersection, right? It's the intersection of these two sets.\\nReturns all records where there is [00:05:00] a match in both tables. Hence no nos. And then we have full join which corresponds to the union in the set operations, right? Here we have a full join and it's this is the matching column as before, but we'll get all other plant IDs as well. But they will be nolls ~~where ~~where there are missing values, right?\\nReturns all records from both tables. If there's no match, nolls are used on non-matching table. Here we see that water schedule and sunlight. They don't exist for two and five. There are nulls and here the plant ID and plant name and type, they don't exist ~~in the in the ~~in the left one for yeah.\\nThey don't exist there. Why doesn't the six exist here? Yes, because we have picked here. P plant ID and not pc plant id. That's why it's missing the six here. [00:06:00] Nos, right? These are nos as well. , Then we got come into something called cross join in S scale, L in in Venn diagrams.\\nIt looks like this. You have all the rows here from table A and all the rows in table B. And it works like row a row row one. In table one is combined with. One and two. Row two is combined with one and two. Row three is combined with one and two, et cetera. This means that it would become something called a Cartesian product.\\nLet's look into that, how it looks and looks like this. If you have this the plant and you do the cross join plant and plant care, you do cross join and you'll see something like this. This is not the full list. This is not a full result. Instead you'll see here that you can see rose oak to lip, cactus, sunflower.\\nThese are the five from the plant, and it's combined with the first one here. You can see daily. [00:07:00] And the first one here, full sun. And then next one is rose will be combined with weekly. Weekly impartial sun, and then that, rose, tulip, cactus, sunflower.\\nThey're combined with weekly and ~~they're combined with ~~partial sun. And then later on ~~we have. ~~We have similarly here, like rose to sunflower. They're combined with biweekly and full sun, et cetera. Yes. Cross join, like right now, I just show you ~~how ~~how the result is. But there are actually quite nice application with cross joinin that for example when you want to.\\nUN nests un nests JSON structure json data, which actually I have~~ I have it in ~~in the appendix~~ a one appendix which is duct DB tricks, ~~where you'll see a case where I use the cross join to ~~actually unst. SKL ~~that ~~the J ~~data. That is quite cool. , Here you can see returns, ~~all records, joints all record joints.~~\\nAll rows from left table with all rows in right [00:08:00] table. That is how cross joints work. Yes.\\nin this video we have gone through SQL joints. They work in db, but they work in ~~other ~~other SQL languages as well. The concepts and intuition behind them, and I hope that~~ you, ~~you have also connected it to, set operations that we learned before and the set theory that you may have learned in mathematics.\\nNote that in~~ SKL ~~joints, it's about the columns while the set operations in s scale, they're about the rows. These are the difference, main difference that you should know about. And then we talk about different types of joints. We had ~~like ~~inner joint, we had left joint, right joint, and we also full.\\n~~Full ~~join and cross joins. These were a few joins that we talked about, and ~~you ~~as you saw in the slides, ~~there were some like, depend ~~depending on which type of joins you have, ~~you get, ~~you will get ~~like ~~null values~~ when, ~~when there's missing in ~~order ~~table, right? ~~This ~~I hope that you've learned a lot in this video and see you in the next one.\\nBye.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db[\"youtube\"].search(\"sql joins\").limit(3).to_list()[0][\"content\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineer-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
