{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86446f20",
   "metadata": {},
   "source": [
    "### Trying to convert markdown into clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e04e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fastapi CRUD app\n",
      "\n",
      "**Kokchun Giang:** [00:00:00] Hello and welcome to this video where we'll go into Fast API in Python. This is a way to create ~~an ~~A ~~PIA ~~rest API and that is what we'll be creating a ~~acru ~~application for. For a library or for books that we can serve books, data. And if you've seen some of my videos before, in a previous video, I used pedantic together with Gemini in order to generate the JSON datas in a structured way.\n",
      "\n",
      "And then I simulated a lot of books data. Now the idea is that I will pick this JSON data and then I will continue on to work and build. An API that we can serve these books to a front end. And then since it's an API, the backend is in Python, we create the backend where we do different data processing.\n",
      "\n",
      "We create the API, which is a layer in between our backend and. Any front end application. You could [00:01:00] use, for example you could use React, you could use Typi, you could use Plotly, you could Plotly Dash, you could use streamlet, et cetera. Or you can use yeah, whatever you want as a front end and just connect to this API.\n",
      "\n",
      "That is the idea. But this is, a very basic one. We'll create a crud application now.\n",
      "\n",
      "**Kokchun Giang-1:** here I am in Visual Studio Code and~~ besides, ~~besides this data here, it's empty. This is from a previous video where we used the Gemini ~~together with ap ~~together with Edan in order to create structured JSON data. And what we did was the library do Jason. Here you can see ulu Library, and here we get all the books.\n",
      "\n",
      "And the only difference is that from that video is that I added IDs. I've added IDs for each of the books. Otherwise, it's the same data as we've gotten from that video. I will link that in the description as well. Otherwise, this is a completely empty repository or completely [00:02:00] empty folder.\n",
      "\n",
      "And we create a terminal here. We'll create a new virtual environment, UVNV, and then Source Van Beam Activate. We activated it. We have fast API crud. This is, we will create the crud, API. That means create, read, update, and delete. In order to do that we will start with installing. UV PIP installed we will need to have let's see, what do we need?\n",
      "\n",
      "We need to have fast API, of course, UV corn to run fast. API. And we need we can start with this one. And if we need something else, we'll install it on the way. Okay, then let's start with creating our A-P-I-A-P dot pi. And here from fast API import fast, API we will also do like this. We will create a.\n",
      "\n",
      "Constance Stance pi, and inside of the [00:03:00] Constance Pi, I need to have the data path. From path lib, import path, remember, we're in normal Python script, and in order to define a path here, we will need to have path lib. Then data path. Data path equals to path of d the file. It's this is path to this constant PI and then dot parent.\n",
      "\n",
      "And then you can, you are in fast, API crud. You can see all of these folders. And I will go into the data folder. Then this data path exists here we can import it in in elsewhere. And also let's see. We will need to have I will need to have another script here. I'll create another script called DataCore Processing pi.\n",
      "\n",
      "The reason for doing this is that I don't want to put everything into my API module. I want to separate it and and make it more [00:04:00] scalable. We will start with reading in the data. Import j we will take from Constance import data path and then we will do def read Jason, and here I'll place in the fine name and with open data path slash fine name.\n",
      "\n",
      "And I want to ~~read it. ~~Read it. We take R as file, and then data equal to js dot load file. And then we return data basically like that. We can try this out. If d the name equals to D the main, then we'll do read Jason. And what do we want to place in? What is this called? It's called Library [00:05:00] Jason.\n",
      "\n",
      "Library J data goes to this, and then I will print the data and I'll run this one. Okay. You can see we have the data here. If we want to print a little bit nicely, we can do from P print, import P print. And then instead of print, I will do p print instead. Clear the terminal and run it again. Okay.\n",
      "\n",
      "Yeah, it still looked, oh. I had print here. P print. Oh yeah. Now it looks better. You can see books. We have. Name also. But in inside of books we have a list of dictionaries. It's a list of dictionaries. Since it's a list of dictionary, we can do it like this. We can create a class called book.\n",
      "\n",
      "This is our model, our book model. And what we need is from P den [00:06:00] import base model. Base model, comma field. And this book, I will call base model. It's it's inheriting base model. It means that this one will become a a edan model, but it's still a normal class. It's a class, but it's a Edan model as well.\n",
      "\n",
      "Id in. You can see inside of books here, it's for each book you can see we have id, we have author, title, and year. Okay. And then we can have title, it's a string. We can have author. It's a string as well. And we have a year. It's an int and this is a field. I want it to be greater than equals to greater than 1000 and less than equals to this year.\n",
      "\n",
      "2025. And to get this year, we can do current year plus one. And [00:07:00] to get the current year let me just go into Constance and we can do from daytime import daytime, and we can do. Current year equals to date time now year. It means that data processing, we can import that from stance import current year.\n",
      "\n",
      "And what this means is that~~ we have a. We, ~~we want it to be larger than, greater than 1000. And we want it to be less than 2026, since it's 2025 now. This current year will become 2025 and plus one, we'll have 2026. Okay? This is our gigantic model and ~~for ~~for our book. ~~And then we can do, also, we can do.~~\n",
      "\n",
      "Class library. It's a base model and the name is String and [00:08:00] Books is list of book, we have this book here that is a model. Library is having the name and it has several books. If you're not familiar with pedantic, make sure to take a look into my pedantic videos ~~before ~~because~~ they will, ~~they are the foundation for fast API fast.\n",
      "\n",
      "API uses pedantic a lot for validating the data. Then we have. Library here, and we can also do like this. We can do deaf library data or file name and then Jason. Jason. Data equals to read Jason. I use the read Jason by placing the fine name and then return library. ~~Model validate ~~model, validate JSON data.\n",
      "\n",
      "Okay, this means that [00:09:00] the library will ~~we, ~~we can do library data. It will read this ~~Jason ~~file. And get this JSON data. And then we'll do library do model validate. This means that instead of doing ~~re ~~json like this, we can try this out by doing library equals to library data of let's see, what's it called?\n",
      "\n",
      "Library J.\n",
      "\n",
      "And we can take a look into library. What does that look like? If I run this one, you can see it's a library object where we have the name Ulu Library, we have books. And we have all the books here. And each of the books contain a book object or a book instance where we have ID title, we have author and year.\n",
      "\n",
      "These [00:10:00] are all ~~edan ~~models. All the book are the models. Library is a pedantic model. That means that we have already validated the data that it comes into the ~~right ~~right fields. We have in string and we have interior with the correct fields here. If you, for example, take a look, for example, if we take 19 ~~hundreds ~~here, we'll have a fail here because you can see there's a lot of books here.\n",
      "\n",
      "Books one year. You can see input should be greater than 1900 books. Five point year input should be greater than 1900, et cetera. And here you can see it's 18 13, 18 51. You can see there is, it's validating the data, but ~~the ~~I want to make it simple. I just take 1000 here. If I run this one, it should be fine because all have years greater than 1000.\n",
      "\n",
      "Okay, for this I'm quite satisfied with the data processing. Let's move on to our API. Inside of the API dot [00:11:00] pi, you start with creating an app equals to fast API. ~~This ~~now we have a fast API application, and then. What we should do also is that we'll read in the data. I can do it before actually library equals to, from data processing, import library data, and we can do library data here.\n",
      "\n",
      "~~Library J. ~~Then we have the library, and then we can get the books. And if you see library to get the books, we do library, do books, library dot books. And basically now you can p print the, ~~let's see, ~~we need to import P print from P print, import, P print. And we can do p print of books. If I just run this one, you can see here are all the books and it's a list of the books.\n",
      "\n",
      "~~Good. ~~And we can now we have our Fast API application and we can create our [00:12:00] first endpoint. At app get. If I go into my URL and I do ~~slash. My first endpoint ~~slash books, I should read all the books, this is a decorator, it'll decorate a function that makes it into ~~a a end ~~an endpoint with the GET request.\n",
      "\n",
      "Get is~~ sim, it's ~~the read operation in crud. Create, read, update, delete. ~~We'll create, ~~this is a get request, then you do async dev and async is to make the the function asynchronous that it doesn't get stuck when when running this one. But fast. API actually makes all the endpoints into async by default, but I type it out to make it extra clear.\n",
      "\n",
      "Async dev read books. Return books basically. Let's try out this endpoint. To try it out, you do like this. You have activated your virtual environment. You have installed UV, corn and [00:13:00] fast API. Let's do UV corn api, pi API Colon app. ~~API is this API. ~~You don't~~ in ~~include the dot pi and then you take what the fast API application's name, which is app, and then that dash reload.\n",
      "\n",
      "You don't need to run it each time you change the code. I run this one and what we get is a server that runs on ~~8,000, ~~port 8,000. ~~I run this one. ~~I will have this side by side. I will make this a little bit bigger and this a little bit smaller like this.\n",
      "\n",
      "Actually, I will have this run out like this. Okay? Right now it says detail not found, but if you do slash books, you can see, ah, these are our books. Wow. Cool. Okay, we can click indented write out the indented code.\n",
      "\n",
      "**Kokchun Giang-2:** Yes. Much cooler. Now it's indented. You can read the data very clearly. Okay, what is the point with [00:14:00] this? When you have it you serve it in API like this. You have a URL, and you can use this URL to do, get request. For example~~ if you ~~if you are in a Jupyter Notebook and you do request on this data.\n",
      "\n",
      "~~You will get this data back. You do request on this URL, ~~you will get this data back and that means that you can serve this to ~~a ~~a frontend application without problems. Let's show you. Another very neat thing is in fast API, there is something called Swagger ui. You go into slash docs and you come into this documentation page here in Fast, API, and you can see there's this get request here.\n",
      "\n",
      "You can click here and you can try it out and you can execute it. And what you can see here is that to do curl. You do type like this and curl is basically what you type in your terminal. If I create a new terminal here and I paste this in this curl, and you can see I get the data. Cool. [00:15:00] And you can, this is the request, URL.\n",
      "\n",
      "As you saw before, we have this URL and then stash books. Then ~~we get into this ~~we get the data we can copy this one and you can see we open here. And you can see we get the data good. And then the response, you can get it here. When you have Swagger ui, you can directly interact with your API through this user interface.\n",
      "\n",
      "And this is really neat. You don't need to have a third party tool such as Postman or some other ~~to ~~tools. You can do it directly here. Okay? Let us continue building on our API. We'll create something called a path parameter. And the path parameter, you should place it before your query parameters.\n",
      "\n",
      "I'll show you what ~~per ~~query parameters is also. App get slash books. We still go into [00:16:00] slash books and then we go into title. And we go into, we type in the title. This is how you do path Parameter. You have curly braces of ~~your your what you want to ~~what the variable should be, what the string should be after the slash title.\n",
      "\n",
      "This one will go into Async f Read book by title. And then you will take the title, it's a string and we should return book for book in books. If book do, title do case fold. Case fold, makes it lowercase equals two. Title case fold. It's lowercase.\n",
      "\n",
      "Let me make it a little bit bigger. What it does is that we have book ~~four ~~[00:17:00] book in books. We get all the books by this title. Where the book, ~~the ~~title equals to. Title case fold. It means that we can type in books with capital letters and it doesn't matter, it will be translated.\n",
      "\n",
      "Let's restart this one. You can see, oh, we get another get request there. Try this out and you can see in Swagger ui you can just type in the title. What title do we have? The Great Gatsby. The great Gaby. Let me just type it like this and show that it works. Anyway, execute, and you can see we get back this de Great Gatsby f Scott Fitzgerald.\n",
      "\n",
      "Okay, here you can see this is the URL there. And then we have percentage, 20, great percentage, 20 Gatsby. Percentage, 20 means [00:18:00] space. This is the URL. If you copy this URL and you go into here, you can see we get this data back. It works. Okay, let's continue. This was a path parameter. You could do ~~per ~~parameters or IDs also if you want.\n",
      "\n",
      "Now let's do a ~~query parameter. ~~Query parameter. It'll, it means that you have a question mark after your endpoint. Start on this, ~~or year ~~I will use this one equals 1950, for example, if you do this. Then this variable start year equals 1950 will be used in our endpoint. At app get slash books slash this one here, we'll go into the books and put in our question mark.\n",
      "\n",
      "Let's [00:19:00] see, async dev filter books ~~and. ~~And what I want to do is start here. This is an int equals to let me import. ~~Query. Query. It's for query, pars ~~query. For default value. This is similar to using the field~~ in in, ~~in pedantic. Query, I want it to be by default, 1950 greater equals to say 1500 less than equals to Let's take current year.\n",
      "\n",
      "From Constance import current year, this equals current year plus one.\n",
      "\n",
      "And then I will also have a description,\n",
      "\n",
      "~~the script, ~~the description equals [00:20:00] to filters, books that are newer than this year. ~~Okay. ~~Okay. Let's see. This is my ~~deaf ~~and I will do filtered books equals to book for book in books. If start year is less than book ~~thought ~~year. Basically like this. Okay, I filter these books and what we do is that we want to return filtered books.\n",
      "\n",
      "Okay? Save this one. Go into swagger, ui, update it. And you can see here we have filter books. I test this out. Okay, try 1950, execute. And you saw that. Okay. We don't get [00:21:00] any books back. Let's see why. Book for book in books. If start year is less than book that year book that year and start year is an int.\n",
      "\n",
      "Oh, I haven't, oh. I have run it. It's, it is run. Okay. I saved this one.\n",
      "\n",
      "Try it out. Filter books that are new than this year. 1950. Execute. I get back nothing. Let me see why. Less than greater than 1500. Less than. 2051. 2026. Filter. This book? Yeah. Oh, okay. Filter book. Ah, filter books. Yeah. I return this function. Of course it doesn't give anything. [00:22:00] Okay. Execute this one and it works.\n",
      "\n",
      "And you can see all of them are newer than 1950. If I take, for example, 90 55 here. We will not get a lot of the rings. If I run this one, we'll only get these two. Okay, great. It works. Now we filter by this, but if you want, you can also, we can see this is the URL, you have slash books, and then we have question marks.\n",
      "\n",
      "Start year equals 90 55. If we want, we can put in more parameters to to query parameters we can have author also if we want. Author is a string. It's a query. None you don't play. It makes it optional. And then we can have a description authors first name and last name. Filter by author's, first name and last name.[00:23:00] \n",
      "\n",
      "Okay, this is the description and we have author and then we can filter the book. If author, it means it's not none, then filtered books equals to this list. Book for book in filtered books. If author.case fold. Equals to book author case fold. Then we return these books here, save this one or update this one.\n",
      "\n",
      "You can see now author comes in as well. Try it out and you can see if we just take 1950 and execute it, it works. ~~Because we haven't ~~because this is it has none as the fault, it's optional. But if I put in an author, for example, Douglas Adams. Douglas Adams [00:24:00] execute it, you can see we get only this one back.\n",
      "\n",
      "Good. This one works. Now we only use the get requests. We are still in read. If we want to create a crud operations, we should do create as well. To do create, we do app post. What you want to do is ~~you want to put in a, ~~you want to post a new book. Books slash create book. And here, async Deaf, great book request.\n",
      "\n",
      "You want to put in a new book as a J object, and this should be book.\n",
      "\n",
      "Okay, and ~~we don't have books, ~~we need to import this one import book. This is the Edan model. It means that it has to conform to the, to, to the fields in the Edan model in order for it to create a new book and then [00:25:00] to create a new book. It's as simple as this new book equals to book model.\n",
      "\n",
      "A ~~book is a, remember the ~~book is a pedantic model, we can ~~do model ~~validate our book request. Just to make sure we turn it into ~~a. ~~A book object. And then what we do is books that append new book. And remember that we append the book. We have our books ~~contains a lot of they ~~contains book objects that are pedantic models.\n",
      "\n",
      "However, when we serve it in the API remember that it gives us ~~chase in ~~data. And what it does is that fast API automatically. ~~It ~~converts it ~~into ~~into JSON data, and that is very good. We have return new book because this is good to do. ~~When you ~~when you basically, you have appended it into your books.\n",
      "\n",
      "That when you do [00:26:00] get request, you will see the new book as well. However when you do post you want to return a new book to show you that it's the new book that is placed in. Let's update this one, and now you can see there's a post. Go into here. We try this out and these are example values you can see.\n",
      "\n",
      "Id zero now. We haven't done ~~any ~~any validation on the id. You could do that. ~~14, ~~for example, title is a string. ~~And what is this? ~~This example is based on our P model. You can see our book model here. It's an int that's why they have a value here, a string. It's also an author.\n",
      "\n",
      "It's also string. You got the value as strings here and int you get this field. Here. ~~Let us make this let us just try or ~~let us make this more helpful. In the documentation. To do that, we go into our data processing and into our book model, [00:27:00] and we'll do something called model config.\n",
      "\n",
      "It's a dictionary, Jason Schema Extra. This is another dictionary. And here we have an example and. Which is non dictionary. And now the example, let's take ID colon 11. We have a title right then with a engineer,\n",
      "\n",
      "author co yang here. 2025. Save this one\n",
      "\n",
      "and let us try it out now. If I update this one, you can see, ah, this is the example values. Good. Try it out. And you can see this example values. Yeah, [00:28:00] we can use this directly. Execute, and you can see that. The response body, it gives back this one. This is the response after we have posted it. Okay.\n",
      "\n",
      "But let's see if this book is there. Read books, try it out, execute. You can see down here. Ah, 11. Learn with Engineer K Young. Okay, cool. Our post request works. And also you can try it out here if you want to read all books.\n",
      "\n",
      "You can see that. Yeah, it's here. Now we have posted the data and let us continue now. We have. Create is post in in fast, API and we can do at app update. This is the update and we can slash books [00:29:00] slash up update book, async dev update book. Updated book. It's a book object, a book model for I book in enumerate books.\n",
      "\n",
      "This means that we'll get indexes for each of the books. And then if book ID equals to Id.\n",
      "\n",
      "Let's see if book ID equals ~~updated book id, ~~updated book id. If this is the case, then books of I equals the updated book. ~~Okay, it means that. We will update ~~we will create~~ when we update we put in ~~a JSON object and the JS ~~O ~~will [00:30:00] take a look into the id. If it's the same ID as another book that exists, then we'll update that book.\n",
      "\n",
      "Otherwise, we won't do anything. After that, we return our updated book. ~~Okay. ~~Fast. API don't let's see. Oh it's not called update. It's called put in fast. API ~~it's called Put. ~~Okay, let us try to change ID 10 here. In my, put, try it out. Let's change Id 10 to. Okay, cool Book. And I've written it, execute it and it returns back this updated book.\n",
      "\n",
      "Let's look into here. This is my slash books here. If I run this one, you can see, ah, I did 10. [00:31:00] Cool book. And why did my 11 disappear? Yeah, because I have reloaded it. Then the data is not stored in the j per se, we haven't done logic for that in, instead it's just for this run here.\n",
      "\n",
      "If you want it to be stored, you should connect it to a database, but I won't show it here. We have done update book. What is left is that we need to delete book. Then we have our cred application. App delete slash books slash delete book slash id. This is a what's called, it's a, puff parameter, async deaf delete book, and it should take in the ID [00:32:00] as an ink and for I comma book in enumerate books. If book id. Equals id. Then we delete this book, books of I Break. Okay, let's try this out. ~~Update this one. ~~Delete id. Let's remove one. Execute.\n",
      "\n",
      "If we go back here and take a look into all the books. You can see ID one has disappeared. Let's remove ID five as well. Five execute. And now we need to rerun this one. Execute. And you can see five has disappeared. Cool. This is our fast API application\n",
      "\n",
      "**Kokchun Giang-3:** We have created our [00:33:00] first CRUD application ~~using ~~using Fast API. ~~And ~~here we have worked with ~~p we have worked with Jason ~~Data and we have created our. ~~Book API ~~books API, that you can read from the books get requests, you can do posts, you can do update, you can do update by put, and you can do deletes.\n",
      "\n",
      "This is ~~really ~~really interesting ~~and ~~and what you can do later with this is that you can connect this into a frontend application. ~~And ~~and then you can, mix and match and use whatever ~~frontend application you want. ~~Frontend framework. You want ~~to do this that ~~if you want to mix Python with JavaScript, no problems.\n",
      "\n",
      "If you want to mix Python with something else, that's no problem either. You can use Python all the way. ~~Also, ~~that's also possible. There's a lot of opportunities when you work with APIs. It's a layer in between now and this is really interesting and I hope. ~~Hope that ~~you have learned a lot from this video ~~and ~~thank you.\n",
      "\n",
      "See you in the next one. Bye.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from backend.constants import DATA_PATH\n",
    "from markdown import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "md_file = next(DATA_PATH.glob(\"*.md\"))\n",
    "\n",
    "with open(md_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    md_text = f.read()\n",
    "\n",
    "print(md_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3080f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_any_duplicates():\n",
    "    duplicates = list(DATA_PATH.glob(\"*(1).md\"))\n",
    "\n",
    "    if duplicates:\n",
    "        for d in duplicates:\n",
    "            print(\"Removing any potential duplicates\")\n",
    "            d.unlink()\n",
    "\n",
    "\n",
    "def convert_md_txt(md_path):\n",
    "\n",
    "    with open(md_path, 'r', encoding=\"utf-8\") as file:\n",
    "        md_text = file.read()\n",
    "\n",
    "        html = markdown(md_text)\n",
    "        who_even_likes_soup = BeautifulSoup(html, features='html.parser')\n",
    "\n",
    "        return who_even_likes_soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65919384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastapi CRUD app\n",
      "Kokchun Giang: [00:00:00] Hello and welcome to this video where we'll go into Fast API in Python. This is a way to create ~~an ~~A ~~PIA ~~rest API and that is what we'll be creating a ~~acru ~~application for. For a library or for books that we can serve books, data. And if you've seen some of my videos before, in a previous video, I used pedantic together with Gemini in order to generate the JSON datas in a structured way.\n",
      "And then I simulated a lot of books data. Now the idea is that I will pick this JSON data and then I will continue on to work and build. An API that we can serve these books to a front end. And then since it's an API, the backend is in Python, we create the backend where we do different data processing.\n",
      "We create the API, which is a layer in between our backend and. Any front end application. You could [00:01:00] use, for example you could use React, you could use Typi, you could use Plotly, you could Plotly Dash, you could use streamlet, et cetera. Or you can use yeah, whatever you want as a front end and just connect to this API.\n",
      "That is the idea. But this is, a very basic one. We'll create a crud application now.\n",
      "Kokchun Giang-1: here I am in Visual Studio Code and~~ besides, ~~besides this data here, it's empty. This is from a previous video where we used the Gemini ~~together with ap ~~together with Edan in order to create structured JSON data. And what we did was the library do Jason. Here you can see ulu Library, and here we get all the books.\n",
      "And the only difference is that from that video is that I added IDs. I've added IDs for each of the books. Otherwise, it's the same data as we've gotten from that video. I will link that in the description as well. Otherwise, this is a completely empty repository or completely [00:02:00] empty folder.\n",
      "And we create a terminal here. We'll create a new virtual environment, UVNV, and then Source Van Beam Activate. We activated it. We have fast API crud. This is, we will create the crud, API. That means create, read, update, and delete. In order to do that we will start with installing. UV PIP installed we will need to have let's see, what do we need?\n",
      "We need to have fast API, of course, UV corn to run fast. API. And we need we can start with this one. And if we need something else, we'll install it on the way. Okay, then let's start with creating our A-P-I-A-P dot pi. And here from fast API import fast, API we will also do like this. We will create a.\n",
      "Constance Stance pi, and inside of the [00:03:00] Constance Pi, I need to have the data path. From path lib, import path, remember, we're in normal Python script, and in order to define a path here, we will need to have path lib. Then data path. Data path equals to path of d the file. It's this is path to this constant PI and then dot parent.\n",
      "And then you can, you are in fast, API crud. You can see all of these folders. And I will go into the data folder. Then this data path exists here we can import it in in elsewhere. And also let's see. We will need to have I will need to have another script here. I'll create another script called DataCore Processing pi.\n",
      "The reason for doing this is that I don't want to put everything into my API module. I want to separate it and and make it more [00:04:00] scalable. We will start with reading in the data. Import j we will take from Constance import data path and then we will do def read Jason, and here I'll place in the fine name and with open data path slash fine name.\n",
      "And I want to ~~read it. ~~Read it. We take R as file, and then data equal to js dot load file. And then we return data basically like that. We can try this out. If d the name equals to D the main, then we'll do read Jason. And what do we want to place in? What is this called? It's called Library [00:05:00] Jason.\n",
      "Library J data goes to this, and then I will print the data and I'll run this one. Okay. You can see we have the data here. If we want to print a little bit nicely, we can do from P print, import P print. And then instead of print, I will do p print instead. Clear the terminal and run it again. Okay.\n",
      "Yeah, it still looked, oh. I had print here. P print. Oh yeah. Now it looks better. You can see books. We have. Name also. But in inside of books we have a list of dictionaries. It's a list of dictionaries. Since it's a list of dictionary, we can do it like this. We can create a class called book.\n",
      "This is our model, our book model. And what we need is from P den [00:06:00] import base model. Base model, comma field. And this book, I will call base model. It's it's inheriting base model. It means that this one will become a a edan model, but it's still a normal class. It's a class, but it's a Edan model as well.\n",
      "Id in. You can see inside of books here, it's for each book you can see we have id, we have author, title, and year. Okay. And then we can have title, it's a string. We can have author. It's a string as well. And we have a year. It's an int and this is a field. I want it to be greater than equals to greater than 1000 and less than equals to this year.\n",
      "\n",
      "And to get this year, we can do current year plus one. And [00:07:00] to get the current year let me just go into Constance and we can do from daytime import daytime, and we can do. Current year equals to date time now year. It means that data processing, we can import that from stance import current year.\n",
      "\n",
      "And what this means is that~~ we have a. We, ~~we want it to be larger than, greater than 1000. And we want it to be less than 2026, since it's 2025 now. This current year will become 2025 and plus one, we'll have 2026. Okay? This is our gigantic model and ~~for ~~for our book. ~~And then we can do, also, we can do.~~\n",
      "Class library. It's a base model and the name is String and [00:08:00] Books is list of book, we have this book here that is a model. Library is having the name and it has several books. If you're not familiar with pedantic, make sure to take a look into my pedantic videos ~~before ~~because~~ they will, ~~they are the foundation for fast API fast.\n",
      "API uses pedantic a lot for validating the data. Then we have. Library here, and we can also do like this. We can do deaf library data or file name and then Jason. Jason. Data equals to read Jason. I use the read Jason by placing the fine name and then return library. ~~Model validate ~~model, validate JSON data.\n",
      "Okay, this means that [00:09:00] the library will ~~we, ~~we can do library data. It will read this ~~Jason ~~file. And get this JSON data. And then we'll do library do model validate. This means that instead of doing ~~re ~~json like this, we can try this out by doing library equals to library data of let's see, what's it called?\n",
      "Library J.\n",
      "And we can take a look into library. What does that look like? If I run this one, you can see it's a library object where we have the name Ulu Library, we have books. And we have all the books here. And each of the books contain a book object or a book instance where we have ID title, we have author and year.\n",
      "These [00:10:00] are all ~~edan ~~models. All the book are the models. Library is a pedantic model. That means that we have already validated the data that it comes into the ~~right ~~right fields. We have in string and we have interior with the correct fields here. If you, for example, take a look, for example, if we take 19 ~~hundreds ~~here, we'll have a fail here because you can see there's a lot of books here.\n",
      "Books one year. You can see input should be greater than 1900 books. Five point year input should be greater than 1900, et cetera. And here you can see it's 18 13, 18 51. You can see there is, it's validating the data, but ~~the ~~I want to make it simple. I just take 1000 here. If I run this one, it should be fine because all have years greater than 1000.\n",
      "Okay, for this I'm quite satisfied with the data processing. Let's move on to our API. Inside of the API dot [00:11:00] pi, you start with creating an app equals to fast API. ~~This ~~now we have a fast API application, and then. What we should do also is that we'll read in the data. I can do it before actually library equals to, from data processing, import library data, and we can do library data here.\n",
      "~~Library J. ~~Then we have the library, and then we can get the books. And if you see library to get the books, we do library, do books, library dot books. And basically now you can p print the, ~~let's see, ~~we need to import P print from P print, import, P print. And we can do p print of books. If I just run this one, you can see here are all the books and it's a list of the books.\n",
      "~~Good. ~~And we can now we have our Fast API application and we can create our [00:12:00] first endpoint. At app get. If I go into my URL and I do ~~slash. My first endpoint ~~slash books, I should read all the books, this is a decorator, it'll decorate a function that makes it into ~~a a end ~~an endpoint with the GET request.\n",
      "Get is~~ sim, it's ~~the read operation in crud. Create, read, update, delete. ~~We'll create, ~~this is a get request, then you do async dev and async is to make the the function asynchronous that it doesn't get stuck when when running this one. But fast. API actually makes all the endpoints into async by default, but I type it out to make it extra clear.\n",
      "Async dev read books. Return books basically. Let's try out this endpoint. To try it out, you do like this. You have activated your virtual environment. You have installed UV, corn and [00:13:00] fast API. Let's do UV corn api, pi API Colon app. ~~API is this API. ~~You don't~~ in ~~include the dot pi and then you take what the fast API application's name, which is app, and then that dash reload.\n",
      "You don't need to run it each time you change the code. I run this one and what we get is a server that runs on ~~8,000, ~~port 8,000. ~~I run this one. ~~I will have this side by side. I will make this a little bit bigger and this a little bit smaller like this.\n",
      "Actually, I will have this run out like this. Okay? Right now it says detail not found, but if you do slash books, you can see, ah, these are our books. Wow. Cool. Okay, we can click indented write out the indented code.\n",
      "Kokchun Giang-2: Yes. Much cooler. Now it's indented. You can read the data very clearly. Okay, what is the point with [00:14:00] this? When you have it you serve it in API like this. You have a URL, and you can use this URL to do, get request. For example~~ if you ~~if you are in a Jupyter Notebook and you do request on this data.\n",
      "~~You will get this data back. You do request on this URL, ~~you will get this data back and that means that you can serve this to ~~a ~~a frontend application without problems. Let's show you. Another very neat thing is in fast API, there is something called Swagger ui. You go into slash docs and you come into this documentation page here in Fast, API, and you can see there's this get request here.\n",
      "You can click here and you can try it out and you can execute it. And what you can see here is that to do curl. You do type like this and curl is basically what you type in your terminal. If I create a new terminal here and I paste this in this curl, and you can see I get the data. Cool. [00:15:00] And you can, this is the request, URL.\n",
      "As you saw before, we have this URL and then stash books. Then ~~we get into this ~~we get the data we can copy this one and you can see we open here. And you can see we get the data good. And then the response, you can get it here. When you have Swagger ui, you can directly interact with your API through this user interface.\n",
      "And this is really neat. You don't need to have a third party tool such as Postman or some other ~~to ~~tools. You can do it directly here. Okay? Let us continue building on our API. We'll create something called a path parameter. And the path parameter, you should place it before your query parameters.\n",
      "I'll show you what ~~per ~~query parameters is also. App get slash books. We still go into [00:16:00] slash books and then we go into title. And we go into, we type in the title. This is how you do path Parameter. You have curly braces of ~~your your what you want to ~~what the variable should be, what the string should be after the slash title.\n",
      "This one will go into Async f Read book by title. And then you will take the title, it's a string and we should return book for book in books. If book do, title do case fold. Case fold, makes it lowercase equals two. Title case fold. It's lowercase.\n",
      "Let me make it a little bit bigger. What it does is that we have book ~~four ~~[00:17:00] book in books. We get all the books by this title. Where the book, ~~the ~~title equals to. Title case fold. It means that we can type in books with capital letters and it doesn't matter, it will be translated.\n",
      "Let's restart this one. You can see, oh, we get another get request there. Try this out and you can see in Swagger ui you can just type in the title. What title do we have? The Great Gatsby. The great Gaby. Let me just type it like this and show that it works. Anyway, execute, and you can see we get back this de Great Gatsby f Scott Fitzgerald.\n",
      "Okay, here you can see this is the URL there. And then we have percentage, 20, great percentage, 20 Gatsby. Percentage, 20 means [00:18:00] space. This is the URL. If you copy this URL and you go into here, you can see we get this data back. It works. Okay, let's continue. This was a path parameter. You could do ~~per ~~parameters or IDs also if you want.\n",
      "Now let's do a ~~query parameter. ~~Query parameter. It'll, it means that you have a question mark after your endpoint. Start on this, ~~or year ~~I will use this one equals 1950, for example, if you do this. Then this variable start year equals 1950 will be used in our endpoint. At app get slash books slash this one here, we'll go into the books and put in our question mark.\n",
      "Let's [00:19:00] see, async dev filter books ~~and. ~~And what I want to do is start here. This is an int equals to let me import. ~~Query. Query. It's for query, pars ~~query. For default value. This is similar to using the field~~ in in, ~~in pedantic. Query, I want it to be by default, 1950 greater equals to say 1500 less than equals to Let's take current year.\n",
      "From Constance import current year, this equals current year plus one.\n",
      "And then I will also have a description,\n",
      "~~the script, ~~the description equals [00:20:00] to filters, books that are newer than this year. ~~Okay. ~~Okay. Let's see. This is my ~~deaf ~~and I will do filtered books equals to book for book in books. If start year is less than book ~~thought ~~year. Basically like this. Okay, I filter these books and what we do is that we want to return filtered books.\n",
      "Okay? Save this one. Go into swagger, ui, update it. And you can see here we have filter books. I test this out. Okay, try 1950, execute. And you saw that. Okay. We don't get [00:21:00] any books back. Let's see why. Book for book in books. If start year is less than book that year book that year and start year is an int.\n",
      "Oh, I haven't, oh. I have run it. It's, it is run. Okay. I saved this one.\n",
      "Try it out. Filter books that are new than this year. 1950. Execute. I get back nothing. Let me see why. Less than greater than 1500. Less than. 2051. 2026. Filter. This book? Yeah. Oh, okay. Filter book. Ah, filter books. Yeah. I return this function. Of course it doesn't give anything. [00:22:00] Okay. Execute this one and it works.\n",
      "And you can see all of them are newer than 1950. If I take, for example, 90 55 here. We will not get a lot of the rings. If I run this one, we'll only get these two. Okay, great. It works. Now we filter by this, but if you want, you can also, we can see this is the URL, you have slash books, and then we have question marks.\n",
      "Start year equals 90 55. If we want, we can put in more parameters to to query parameters we can have author also if we want. Author is a string. It's a query. None you don't play. It makes it optional. And then we can have a description authors first name and last name. Filter by author's, first name and last name.[00:23:00] \n",
      "Okay, this is the description and we have author and then we can filter the book. If author, it means it's not none, then filtered books equals to this list. Book for book in filtered books. If author.case fold. Equals to book author case fold. Then we return these books here, save this one or update this one.\n",
      "You can see now author comes in as well. Try it out and you can see if we just take 1950 and execute it, it works. ~~Because we haven't ~~because this is it has none as the fault, it's optional. But if I put in an author, for example, Douglas Adams. Douglas Adams [00:24:00] execute it, you can see we get only this one back.\n",
      "Good. This one works. Now we only use the get requests. We are still in read. If we want to create a crud operations, we should do create as well. To do create, we do app post. What you want to do is ~~you want to put in a, ~~you want to post a new book. Books slash create book. And here, async Deaf, great book request.\n",
      "You want to put in a new book as a J object, and this should be book.\n",
      "Okay, and ~~we don't have books, ~~we need to import this one import book. This is the Edan model. It means that it has to conform to the, to, to the fields in the Edan model in order for it to create a new book and then [00:25:00] to create a new book. It's as simple as this new book equals to book model.\n",
      "A ~~book is a, remember the ~~book is a pedantic model, we can ~~do model ~~validate our book request. Just to make sure we turn it into ~~a. ~~A book object. And then what we do is books that append new book. And remember that we append the book. We have our books ~~contains a lot of they ~~contains book objects that are pedantic models.\n",
      "However, when we serve it in the API remember that it gives us ~~chase in ~~data. And what it does is that fast API automatically. ~~It ~~converts it ~~into ~~into JSON data, and that is very good. We have return new book because this is good to do. ~~When you ~~when you basically, you have appended it into your books.\n",
      "That when you do [00:26:00] get request, you will see the new book as well. However when you do post you want to return a new book to show you that it's the new book that is placed in. Let's update this one, and now you can see there's a post. Go into here. We try this out and these are example values you can see.\n",
      "Id zero now. We haven't done ~~any ~~any validation on the id. You could do that. ~~14, ~~for example, title is a string. ~~And what is this? ~~This example is based on our P model. You can see our book model here. It's an int that's why they have a value here, a string. It's also an author.\n",
      "It's also string. You got the value as strings here and int you get this field. Here. ~~Let us make this let us just try or ~~let us make this more helpful. In the documentation. To do that, we go into our data processing and into our book model, [00:27:00] and we'll do something called model config.\n",
      "It's a dictionary, Jason Schema Extra. This is another dictionary. And here we have an example and. Which is non dictionary. And now the example, let's take ID colon 11. We have a title right then with a engineer,\n",
      "author co yang here. 2025. Save this one\n",
      "and let us try it out now. If I update this one, you can see, ah, this is the example values. Good. Try it out. And you can see this example values. Yeah, [00:28:00] we can use this directly. Execute, and you can see that. The response body, it gives back this one. This is the response after we have posted it. Okay.\n",
      "But let's see if this book is there. Read books, try it out, execute. You can see down here. Ah, 11. Learn with Engineer K Young. Okay, cool. Our post request works. And also you can try it out here if you want to read all books.\n",
      "You can see that. Yeah, it's here. Now we have posted the data and let us continue now. We have. Create is post in in fast, API and we can do at app update. This is the update and we can slash books [00:29:00] slash up update book, async dev update book. Updated book. It's a book object, a book model for I book in enumerate books.\n",
      "This means that we'll get indexes for each of the books. And then if book ID equals to Id.\n",
      "Let's see if book ID equals ~~updated book id, ~~updated book id. If this is the case, then books of I equals the updated book. ~~Okay, it means that. We will update ~~we will create~~ when we update we put in ~~a JSON object and the JS ~~O ~~will [00:30:00] take a look into the id. If it's the same ID as another book that exists, then we'll update that book.\n",
      "Otherwise, we won't do anything. After that, we return our updated book. ~~Okay. ~~Fast. API don't let's see. Oh it's not called update. It's called put in fast. API ~~it's called Put. ~~Okay, let us try to change ID 10 here. In my, put, try it out. Let's change Id 10 to. Okay, cool Book. And I've written it, execute it and it returns back this updated book.\n",
      "Let's look into here. This is my slash books here. If I run this one, you can see, ah, I did 10. [00:31:00] Cool book. And why did my 11 disappear? Yeah, because I have reloaded it. Then the data is not stored in the j per se, we haven't done logic for that in, instead it's just for this run here.\n",
      "If you want it to be stored, you should connect it to a database, but I won't show it here. We have done update book. What is left is that we need to delete book. Then we have our cred application. App delete slash books slash delete book slash id. This is a what's called, it's a, puff parameter, async deaf delete book, and it should take in the ID [00:32:00] as an ink and for I comma book in enumerate books. If book id. Equals id. Then we delete this book, books of I Break. Okay, let's try this out. ~~Update this one. ~~Delete id. Let's remove one. Execute.\n",
      "If we go back here and take a look into all the books. You can see ID one has disappeared. Let's remove ID five as well. Five execute. And now we need to rerun this one. Execute. And you can see five has disappeared. Cool. This is our fast API application\n",
      "Kokchun Giang-3: We have created our [00:33:00] first CRUD application ~~using ~~using Fast API. ~~And ~~here we have worked with ~~p we have worked with Jason ~~Data and we have created our. ~~Book API ~~books API, that you can read from the books get requests, you can do posts, you can do update, you can do update by put, and you can do deletes.\n",
      "This is ~~really ~~really interesting ~~and ~~and what you can do later with this is that you can connect this into a frontend application. ~~And ~~and then you can, mix and match and use whatever ~~frontend application you want. ~~Frontend framework. You want ~~to do this that ~~if you want to mix Python with JavaScript, no problems.\n",
      "If you want to mix Python with something else, that's no problem either. You can use Python all the way. ~~Also, ~~that's also possible. There's a lot of opportunities when you work with APIs. It's a layer in between now and this is really interesting and I hope. ~~Hope that ~~you have learned a lot from this video ~~and ~~thank you.\n",
      "See you in the next one. Bye.\n"
     ]
    }
   ],
   "source": [
    "md_file = next(DATA_PATH.glob(\"*.md\"))\n",
    "text = convert_md_txt(md_file)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4ef25",
   "metadata": {},
   "source": [
    "### Exploring txt-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff0756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/t8g0_t_n1_9bcmhw9_c95wnc0000gn/T/ipykernel_6144/3036452005.py:4: DeprecationWarning: table_names() is deprecated, use list_tables() instead\n",
      "  vector_db.table_names()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['YouTube']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "\n",
    "vector_db = lancedb.connect(uri = \"knowledge_base\")\n",
    "vector_db.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f2b8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanceTable(name='youtube', version=108, _conn=LanceDBConnection(uri='/Users/efrem_27/Documents/github/AI_engineer_project/knowledge_base'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db[\"youtube\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c34d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>filepath</th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an introduction to the vector database lancedb</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>an introduction to the vector database lancedb</td>\n",
       "      <td>An introduction to the vector database LanceDB...</td>\n",
       "      <td>[-0.038165595, 0.005839912, 0.02174149, -0.073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data platform course structure</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>data platform course structure</td>\n",
       "      <td>Data platform course structure\\n[00:00:00] Hel...</td>\n",
       "      <td>[0.010596283, 0.0007604208, 0.011798323, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>SQL analytics course with DuckDB - Sakila BI d...</td>\n",
       "      <td>[0.003561765, -0.0024968137, 0.018408697, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic regression theory</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>logistic regression theory</td>\n",
       "      <td>Logistic regression theory\\n[00:00:00] Hello a...</td>\n",
       "      <td>[-0.00641446, 0.0017129751, 0.0117463, -0.0701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data processing course  structure</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>data processing course  structure</td>\n",
       "      <td>data processing course structure\\nKokchun: [00...</td>\n",
       "      <td>[0.0030052175, 0.012903026, 0.0074207284, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>SQL analytics course with DuckDB - pandas and ...</td>\n",
       "      <td>[-0.011264389, -0.009431089, 0.013158852, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>python fundamentals</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>python fundamentals</td>\n",
       "      <td>Python fundamentals\\n[00:00:00] Hello and welc...</td>\n",
       "      <td>[-0.010547567, 0.0052952566, 0.015170559, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pytest unit testing</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pytest unit testing</td>\n",
       "      <td>pytest unit testing\\n[00:00:00] Hello and welc...</td>\n",
       "      <td>[-0.013908745, 0.0010215672, 0.029968578, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pydantic with gemini to structure output in a ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pydantic with gemini to structure output in a ...</td>\n",
       "      <td>Pydantic with gemini to structure output in a ...</td>\n",
       "      <td>[-0.015264044, -0.0024070442, 0.015796792, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logistic regression hands on with scikit learn</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>logistic regression hands on with scikit learn</td>\n",
       "      <td>Logistic regression hands on with scikit learn...</td>\n",
       "      <td>[-0.0069891424, 0.0071438453, 0.012519629, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sql analytics course with duckdb - crud operat...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - crud operat...</td>\n",
       "      <td>SQL analytics course with DuckDB - CRUD operat...</td>\n",
       "      <td>[-0.018761043, 0.002032702, 0.02506354, -0.063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>python_oop_1</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>python_oop_1</td>\n",
       "      <td>Python_oop_1\\nkokchun: [00:00:00] Hello and we...</td>\n",
       "      <td>[-0.007964168, -0.010724814, 0.03142313, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sql analytics course with duckdb - setup duckdb</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - setup duckdb</td>\n",
       "      <td>SQL analytics course with DuckDB - setup duckd...</td>\n",
       "      <td>[-0.007941736, -0.0017214945, 0.017682433, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hands on regularization</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>hands on regularization</td>\n",
       "      <td>Hands on regularization\\n[00:00:00] Hello and ...</td>\n",
       "      <td>[-0.008896271, 0.001761678, 0.023786722, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>course structure for azure two weeks course</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>course structure for azure two weeks course</td>\n",
       "      <td>Course structure for Azure two weeks course\\n[...</td>\n",
       "      <td>[0.0031295605, 0.014166776, 0.016287401, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>SQL analytics course with DuckDB - Sakila BI d...</td>\n",
       "      <td>[0.003561765, -0.0024968137, 0.018408697, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>SQL analytics course with DuckDB - set theory ...</td>\n",
       "      <td>[-0.028066158, -0.019780347, 0.019481514, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pydanticai chatbot</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pydanticai chatbot</td>\n",
       "      <td>pydanticAI chatbot\\n[00:00:00] Hello and welco...</td>\n",
       "      <td>[-0.011707014, -0.0005243588, 0.013498923, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chat with your excel data - xlwings lite (1)</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>chat with your excel data - xlwings lite (1)</td>\n",
       "      <td>Chat with your excel data - xlwings lite\\nKokc...</td>\n",
       "      <td>[-0.0073488248, 0.021756327, 0.016487604, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>modern data stack - using dlt to extract and l...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>modern data stack - using dlt to extract and l...</td>\n",
       "      <td>Modern data stack - using dlt to extract and l...</td>\n",
       "      <td>[-0.009853688, 0.02026993, 0.0176039, -0.08109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data storytelling</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>data storytelling</td>\n",
       "      <td>data storytelling\\n[00:00:00] Hello and welcom...</td>\n",
       "      <td>[-0.009587259, 0.017984493, 0.012533942, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>api trafiklab (1)</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>api trafiklab (1)</td>\n",
       "      <td>API trafiklab\\n[00:00:00] Hello and welcome to...</td>\n",
       "      <td>[-0.004888756, -0.0044691996, 0.014377842, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fastapi crud app</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>fastapi crud app</td>\n",
       "      <td>Fastapi CRUD app\\nKokchun Giang: [00:00:00] He...</td>\n",
       "      <td>[-0.010539368, -0.015074633, 0.022835571, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>api trafiklab</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>api trafiklab</td>\n",
       "      <td>API trafiklab\\n[00:00:00] Hello and welcome to...</td>\n",
       "      <td>[-0.004888756, -0.0044691996, 0.014377842, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sql analytics course with duckdb - joins concepts</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - joins concepts</td>\n",
       "      <td>SQL analytics course with DuckDB - joins conce...</td>\n",
       "      <td>[-0.027226884, -0.016104657, 0.011940904, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fastapi and scikit-learn api connect to stream...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>fastapi and scikit-learn api connect to stream...</td>\n",
       "      <td>FastAPI and scikit-learn API connect to stream...</td>\n",
       "      <td>[-0.016197618, 0.01243914, 0.018560743, -0.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>Serving PydanticAI Gemini Model with FastAPI T...</td>\n",
       "      <td>[-0.017158316, -0.005054007, 0.016186513, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>packaging in python</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>packaging in python</td>\n",
       "      <td>Packaging in python\\n[00:00:00] Hello and welc...</td>\n",
       "      <td>[-0.015012743, 0.005314837, 0.037370495, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>modern data stack - deploy dockerized dashboar...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>modern data stack - deploy dockerized dashboar...</td>\n",
       "      <td>Modern data stack - deploy dockerized dashboar...</td>\n",
       "      <td>[-0.00852369, 0.022943845, 0.027582156, -0.104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>postgres sink</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>postgres sink</td>\n",
       "      <td>postgres sink\\n[00:00:00] Hello and welcome to...</td>\n",
       "      <td>[0.008457462, 0.02178748, 0.032398567, -0.0877...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sql analytics course with duckdb - views tutorial</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - views tutorial</td>\n",
       "      <td>SQL analytics course with DuckDB - views tutor...</td>\n",
       "      <td>[-0.026221767, -0.0056624073, 0.0042914175, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>python intro</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>python intro</td>\n",
       "      <td>python intro\\n[00:00:00] Hello and welcome to ...</td>\n",
       "      <td>[-0.010726931, -0.0021426522, 0.012746945, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>chat with your excel data - xlwings lite</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>chat with your excel data - xlwings lite</td>\n",
       "      <td>Chat with your excel data - xlwings lite\\nKokc...</td>\n",
       "      <td>[-0.0073488248, 0.021756327, 0.016487604, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>docker setup windows</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>docker setup windows</td>\n",
       "      <td>docker setup windows\\n[00:00:00] Hello and wel...</td>\n",
       "      <td>[-0.002607342, 0.011477059, 0.017320504, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sql analytics with duckdb - introduction</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics with duckdb - introduction</td>\n",
       "      <td>SQL analytics with DuckDB - introduction\\n[00:...</td>\n",
       "      <td>[-0.027429162, -0.010124963, 0.006358245, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sql analytics course with duckdb - course stru...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - course stru...</td>\n",
       "      <td>SQL analytics course with DuckDB - course stru...</td>\n",
       "      <td>[0.0023808868, -0.0016924503, 0.0038941107, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>azure static web app deploy react app</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>azure static web app deploy react app</td>\n",
       "      <td>Azure static web app deploy react app\\n[00:00:...</td>\n",
       "      <td>[-0.013259199, 0.017627934, 0.025625126, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>how does llm work_</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>how does llm work_</td>\n",
       "      <td>How does LLM work?\\n[00:00:00] Hello and welco...</td>\n",
       "      <td>[-0.026513925, 0.018813677, 0.023627453, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>terraform setup</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>terraform setup</td>\n",
       "      <td>Terraform setup\\n[00:00:00] Hello and welcome ...</td>\n",
       "      <td>[-0.0044360664, 0.021062179, 0.016942821, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>pandas_read_excel</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pandas_read_excel</td>\n",
       "      <td>pandas_read_excel\\n[00:00:00] Hello and welcom...</td>\n",
       "      <td>[-0.004386253, 0.006513567, 0.024039451, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pydantic fundamentals</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pydantic fundamentals</td>\n",
       "      <td>Pydantic fundamentals\\n[00:00:00] Hello and we...</td>\n",
       "      <td>[-0.01768868, -0.0106104445, 0.021348534, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sql analytics course with duckdb - joins with ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - joins with ...</td>\n",
       "      <td>SQL analytics course with DuckDB - joins with ...</td>\n",
       "      <td>[-0.023188569, -0.020161223, 0.012935176, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pydanticai fundamentals - outputting structure...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>pydanticai fundamentals - outputting structure...</td>\n",
       "      <td>PydanticAI fundamentals - outputting structure...</td>\n",
       "      <td>[-0.03427028, 0.003974868, 0.025365941, -0.076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sql analytics course with duckdb - strings con...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - strings con...</td>\n",
       "      <td>SQL analytics course with DuckDB - strings con...</td>\n",
       "      <td>[-0.025746755, -0.00897205, 0.0034949258, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>SQL analytics course with DuckDB - pandas and ...</td>\n",
       "      <td>[-0.011264389, -0.009431089, 0.013158852, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>SQL analytics course with DuckDB - set theory ...</td>\n",
       "      <td>[-0.028066158, -0.019780347, 0.019481514, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>sql analytics course with duckdb - subquery tu...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - subquery tu...</td>\n",
       "      <td>SQL analytics course with DuckDB - subquery tu...</td>\n",
       "      <td>[-0.01246018, -0.012045197, -0.0021293734, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sql analytics course with duckdb - strings tut...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - strings tut...</td>\n",
       "      <td>SQL analytics course with DuckDB - strings tut...</td>\n",
       "      <td>[-0.021604763, -0.0006556192, 0.009578983, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>dbt modeling snowflake</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>dbt modeling snowflake</td>\n",
       "      <td>dbt modeling snowflake\\nKokchun Giang: [00:00:...</td>\n",
       "      <td>[-0.011131446, 0.013321222, 0.028704425, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>Serving PydanticAI Gemini Model with FastAPI T...</td>\n",
       "      <td>[-0.017158316, -0.005054007, 0.016186513, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sql analytics course with duckdb - dlt to load...</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>sql analytics course with duckdb - dlt to load...</td>\n",
       "      <td>SQL analytics course with DuckDB - dlt to load...</td>\n",
       "      <td>[-0.008279277, -0.0047078263, 0.01916089, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>modern data stack - dockerize your data pipeline</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>modern data stack - dockerize your data pipeline</td>\n",
       "      <td>Modern data stack - dockerize your data pipeli...</td>\n",
       "      <td>[0.0016710534, 0.015011349, 0.026834052, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>xgboost hands on tutorial for classification</td>\n",
       "      <td>/Users/efrem_27/Documents/github/AI_engineer_p...</td>\n",
       "      <td>xgboost hands on tutorial for classification</td>\n",
       "      <td>XGBoost hands on tutorial for classification\\n...</td>\n",
       "      <td>[-0.0050945953, 0.010234255, 0.013902015, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               doc_id  \\\n",
       "0      an introduction to the vector database lancedb   \n",
       "1                      data platform course structure   \n",
       "2   sql analytics course with duckdb - sakila bi d...   \n",
       "3                          logistic regression theory   \n",
       "4                   data processing course  structure   \n",
       "5   sql analytics course with duckdb - pandas and ...   \n",
       "6                                 python fundamentals   \n",
       "7                                 pytest unit testing   \n",
       "8   pydantic with gemini to structure output in a ...   \n",
       "9      logistic regression hands on with scikit learn   \n",
       "10  sql analytics course with duckdb - crud operat...   \n",
       "11                                       python_oop_1   \n",
       "12    sql analytics course with duckdb - setup duckdb   \n",
       "13                            hands on regularization   \n",
       "14        course structure for azure two weeks course   \n",
       "15  sql analytics course with duckdb - sakila bi d...   \n",
       "16  sql analytics course with duckdb - set theory ...   \n",
       "17                                 pydanticai chatbot   \n",
       "18       chat with your excel data - xlwings lite (1)   \n",
       "19  modern data stack - using dlt to extract and l...   \n",
       "20                                  data storytelling   \n",
       "21                                  api trafiklab (1)   \n",
       "22                                   fastapi crud app   \n",
       "23                                      api trafiklab   \n",
       "24  sql analytics course with duckdb - joins concepts   \n",
       "25  fastapi and scikit-learn api connect to stream...   \n",
       "26  serving pydanticai gemini model with fastapi t...   \n",
       "27                                packaging in python   \n",
       "28  modern data stack - deploy dockerized dashboar...   \n",
       "29                                      postgres sink   \n",
       "30  sql analytics course with duckdb - views tutorial   \n",
       "31                                       python intro   \n",
       "32           chat with your excel data - xlwings lite   \n",
       "33                               docker setup windows   \n",
       "34           sql analytics with duckdb - introduction   \n",
       "35  sql analytics course with duckdb - course stru...   \n",
       "36              azure static web app deploy react app   \n",
       "37                                 how does llm work_   \n",
       "38                                    terraform setup   \n",
       "39                                  pandas_read_excel   \n",
       "40                              pydantic fundamentals   \n",
       "41  sql analytics course with duckdb - joins with ...   \n",
       "42  pydanticai fundamentals - outputting structure...   \n",
       "43  sql analytics course with duckdb - strings con...   \n",
       "44  sql analytics course with duckdb - pandas and ...   \n",
       "45  sql analytics course with duckdb - set theory ...   \n",
       "46  sql analytics course with duckdb - subquery tu...   \n",
       "47  sql analytics course with duckdb - strings tut...   \n",
       "48                             dbt modeling snowflake   \n",
       "49  serving pydanticai gemini model with fastapi t...   \n",
       "50  sql analytics course with duckdb - dlt to load...   \n",
       "51   modern data stack - dockerize your data pipeline   \n",
       "52       xgboost hands on tutorial for classification   \n",
       "\n",
       "                                             filepath  \\\n",
       "0   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "1   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "2   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "3   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "4   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "5   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "6   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "7   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "8   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "9   /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "10  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "11  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "12  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "13  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "14  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "15  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "16  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "17  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "18  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "19  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "20  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "21  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "22  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "23  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "24  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "25  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "26  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "27  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "28  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "29  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "30  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "31  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "32  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "33  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "34  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "35  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "36  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "37  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "38  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "39  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "40  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "41  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "42  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "43  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "44  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "45  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "46  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "47  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "48  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "49  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "50  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "51  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "52  /Users/efrem_27/Documents/github/AI_engineer_p...   \n",
       "\n",
       "                                             filename  \\\n",
       "0      an introduction to the vector database lancedb   \n",
       "1                      data platform course structure   \n",
       "2   sql analytics course with duckdb - sakila bi d...   \n",
       "3                          logistic regression theory   \n",
       "4                   data processing course  structure   \n",
       "5   sql analytics course with duckdb - pandas and ...   \n",
       "6                                 python fundamentals   \n",
       "7                                 pytest unit testing   \n",
       "8   pydantic with gemini to structure output in a ...   \n",
       "9      logistic regression hands on with scikit learn   \n",
       "10  sql analytics course with duckdb - crud operat...   \n",
       "11                                       python_oop_1   \n",
       "12    sql analytics course with duckdb - setup duckdb   \n",
       "13                            hands on regularization   \n",
       "14        course structure for azure two weeks course   \n",
       "15  sql analytics course with duckdb - sakila bi d...   \n",
       "16  sql analytics course with duckdb - set theory ...   \n",
       "17                                 pydanticai chatbot   \n",
       "18       chat with your excel data - xlwings lite (1)   \n",
       "19  modern data stack - using dlt to extract and l...   \n",
       "20                                  data storytelling   \n",
       "21                                  api trafiklab (1)   \n",
       "22                                   fastapi crud app   \n",
       "23                                      api trafiklab   \n",
       "24  sql analytics course with duckdb - joins concepts   \n",
       "25  fastapi and scikit-learn api connect to stream...   \n",
       "26  serving pydanticai gemini model with fastapi t...   \n",
       "27                                packaging in python   \n",
       "28  modern data stack - deploy dockerized dashboar...   \n",
       "29                                      postgres sink   \n",
       "30  sql analytics course with duckdb - views tutorial   \n",
       "31                                       python intro   \n",
       "32           chat with your excel data - xlwings lite   \n",
       "33                               docker setup windows   \n",
       "34           sql analytics with duckdb - introduction   \n",
       "35  sql analytics course with duckdb - course stru...   \n",
       "36              azure static web app deploy react app   \n",
       "37                                 how does llm work_   \n",
       "38                                    terraform setup   \n",
       "39                                  pandas_read_excel   \n",
       "40                              pydantic fundamentals   \n",
       "41  sql analytics course with duckdb - joins with ...   \n",
       "42  pydanticai fundamentals - outputting structure...   \n",
       "43  sql analytics course with duckdb - strings con...   \n",
       "44  sql analytics course with duckdb - pandas and ...   \n",
       "45  sql analytics course with duckdb - set theory ...   \n",
       "46  sql analytics course with duckdb - subquery tu...   \n",
       "47  sql analytics course with duckdb - strings tut...   \n",
       "48                             dbt modeling snowflake   \n",
       "49  serving pydanticai gemini model with fastapi t...   \n",
       "50  sql analytics course with duckdb - dlt to load...   \n",
       "51   modern data stack - dockerize your data pipeline   \n",
       "52       xgboost hands on tutorial for classification   \n",
       "\n",
       "                                              content  \\\n",
       "0   An introduction to the vector database LanceDB...   \n",
       "1   Data platform course structure\\n[00:00:00] Hel...   \n",
       "2   SQL analytics course with DuckDB - Sakila BI d...   \n",
       "3   Logistic regression theory\\n[00:00:00] Hello a...   \n",
       "4   data processing course structure\\nKokchun: [00...   \n",
       "5   SQL analytics course with DuckDB - pandas and ...   \n",
       "6   Python fundamentals\\n[00:00:00] Hello and welc...   \n",
       "7   pytest unit testing\\n[00:00:00] Hello and welc...   \n",
       "8   Pydantic with gemini to structure output in a ...   \n",
       "9   Logistic regression hands on with scikit learn...   \n",
       "10  SQL analytics course with DuckDB - CRUD operat...   \n",
       "11  Python_oop_1\\nkokchun: [00:00:00] Hello and we...   \n",
       "12  SQL analytics course with DuckDB - setup duckd...   \n",
       "13  Hands on regularization\\n[00:00:00] Hello and ...   \n",
       "14  Course structure for Azure two weeks course\\n[...   \n",
       "15  SQL analytics course with DuckDB - Sakila BI d...   \n",
       "16  SQL analytics course with DuckDB - set theory ...   \n",
       "17  pydanticAI chatbot\\n[00:00:00] Hello and welco...   \n",
       "18  Chat with your excel data - xlwings lite\\nKokc...   \n",
       "19  Modern data stack - using dlt to extract and l...   \n",
       "20  data storytelling\\n[00:00:00] Hello and welcom...   \n",
       "21  API trafiklab\\n[00:00:00] Hello and welcome to...   \n",
       "22  Fastapi CRUD app\\nKokchun Giang: [00:00:00] He...   \n",
       "23  API trafiklab\\n[00:00:00] Hello and welcome to...   \n",
       "24  SQL analytics course with DuckDB - joins conce...   \n",
       "25  FastAPI and scikit-learn API connect to stream...   \n",
       "26  Serving PydanticAI Gemini Model with FastAPI T...   \n",
       "27  Packaging in python\\n[00:00:00] Hello and welc...   \n",
       "28  Modern data stack - deploy dockerized dashboar...   \n",
       "29  postgres sink\\n[00:00:00] Hello and welcome to...   \n",
       "30  SQL analytics course with DuckDB - views tutor...   \n",
       "31  python intro\\n[00:00:00] Hello and welcome to ...   \n",
       "32  Chat with your excel data - xlwings lite\\nKokc...   \n",
       "33  docker setup windows\\n[00:00:00] Hello and wel...   \n",
       "34  SQL analytics with DuckDB - introduction\\n[00:...   \n",
       "35  SQL analytics course with DuckDB - course stru...   \n",
       "36  Azure static web app deploy react app\\n[00:00:...   \n",
       "37  How does LLM work?\\n[00:00:00] Hello and welco...   \n",
       "38  Terraform setup\\n[00:00:00] Hello and welcome ...   \n",
       "39  pandas_read_excel\\n[00:00:00] Hello and welcom...   \n",
       "40  Pydantic fundamentals\\n[00:00:00] Hello and we...   \n",
       "41  SQL analytics course with DuckDB - joins with ...   \n",
       "42  PydanticAI fundamentals - outputting structure...   \n",
       "43  SQL analytics course with DuckDB - strings con...   \n",
       "44  SQL analytics course with DuckDB - pandas and ...   \n",
       "45  SQL analytics course with DuckDB - set theory ...   \n",
       "46  SQL analytics course with DuckDB - subquery tu...   \n",
       "47  SQL analytics course with DuckDB - strings tut...   \n",
       "48  dbt modeling snowflake\\nKokchun Giang: [00:00:...   \n",
       "49  Serving PydanticAI Gemini Model with FastAPI T...   \n",
       "50  SQL analytics course with DuckDB - dlt to load...   \n",
       "51  Modern data stack - dockerize your data pipeli...   \n",
       "52  XGBoost hands on tutorial for classification\\n...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.038165595, 0.005839912, 0.02174149, -0.073...  \n",
       "1   [0.010596283, 0.0007604208, 0.011798323, -0.07...  \n",
       "2   [0.003561765, -0.0024968137, 0.018408697, -0.0...  \n",
       "3   [-0.00641446, 0.0017129751, 0.0117463, -0.0701...  \n",
       "4   [0.0030052175, 0.012903026, 0.0074207284, -0.0...  \n",
       "5   [-0.011264389, -0.009431089, 0.013158852, -0.0...  \n",
       "6   [-0.010547567, 0.0052952566, 0.015170559, -0.0...  \n",
       "7   [-0.013908745, 0.0010215672, 0.029968578, -0.0...  \n",
       "8   [-0.015264044, -0.0024070442, 0.015796792, -0....  \n",
       "9   [-0.0069891424, 0.0071438453, 0.012519629, -0....  \n",
       "10  [-0.018761043, 0.002032702, 0.02506354, -0.063...  \n",
       "11  [-0.007964168, -0.010724814, 0.03142313, -0.06...  \n",
       "12  [-0.007941736, -0.0017214945, 0.017682433, -0....  \n",
       "13  [-0.008896271, 0.001761678, 0.023786722, -0.07...  \n",
       "14  [0.0031295605, 0.014166776, 0.016287401, -0.07...  \n",
       "15  [0.003561765, -0.0024968137, 0.018408697, -0.0...  \n",
       "16  [-0.028066158, -0.019780347, 0.019481514, -0.0...  \n",
       "17  [-0.011707014, -0.0005243588, 0.013498923, -0....  \n",
       "18  [-0.0073488248, 0.021756327, 0.016487604, -0.0...  \n",
       "19  [-0.009853688, 0.02026993, 0.0176039, -0.08109...  \n",
       "20  [-0.009587259, 0.017984493, 0.012533942, -0.08...  \n",
       "21  [-0.004888756, -0.0044691996, 0.014377842, -0....  \n",
       "22  [-0.010539368, -0.015074633, 0.022835571, -0.0...  \n",
       "23  [-0.004888756, -0.0044691996, 0.014377842, -0....  \n",
       "24  [-0.027226884, -0.016104657, 0.011940904, -0.0...  \n",
       "25  [-0.016197618, 0.01243914, 0.018560743, -0.085...  \n",
       "26  [-0.017158316, -0.005054007, 0.016186513, -0.0...  \n",
       "27  [-0.015012743, 0.005314837, 0.037370495, -0.07...  \n",
       "28  [-0.00852369, 0.022943845, 0.027582156, -0.104...  \n",
       "29  [0.008457462, 0.02178748, 0.032398567, -0.0877...  \n",
       "30  [-0.026221767, -0.0056624073, 0.0042914175, -0...  \n",
       "31  [-0.010726931, -0.0021426522, 0.012746945, -0....  \n",
       "32  [-0.0073488248, 0.021756327, 0.016487604, -0.0...  \n",
       "33  [-0.002607342, 0.011477059, 0.017320504, -0.07...  \n",
       "34  [-0.027429162, -0.010124963, 0.006358245, -0.0...  \n",
       "35  [0.0023808868, -0.0016924503, 0.0038941107, -0...  \n",
       "36  [-0.013259199, 0.017627934, 0.025625126, -0.09...  \n",
       "37  [-0.026513925, 0.018813677, 0.023627453, -0.06...  \n",
       "38  [-0.0044360664, 0.021062179, 0.016942821, -0.0...  \n",
       "39  [-0.004386253, 0.006513567, 0.024039451, -0.06...  \n",
       "40  [-0.01768868, -0.0106104445, 0.021348534, -0.0...  \n",
       "41  [-0.023188569, -0.020161223, 0.012935176, -0.0...  \n",
       "42  [-0.03427028, 0.003974868, 0.025365941, -0.076...  \n",
       "43  [-0.025746755, -0.00897205, 0.0034949258, -0.0...  \n",
       "44  [-0.011264389, -0.009431089, 0.013158852, -0.0...  \n",
       "45  [-0.028066158, -0.019780347, 0.019481514, -0.0...  \n",
       "46  [-0.01246018, -0.012045197, -0.0021293734, -0....  \n",
       "47  [-0.021604763, -0.0006556192, 0.009578983, -0....  \n",
       "48  [-0.011131446, 0.013321222, 0.028704425, -0.08...  \n",
       "49  [-0.017158316, -0.005054007, 0.016186513, -0.0...  \n",
       "50  [-0.008279277, -0.0047078263, 0.01916089, -0.0...  \n",
       "51  [0.0016710534, 0.015011349, 0.026834052, -0.09...  \n",
       "52  [-0.0050945953, 0.010234255, 0.013902015, -0.0...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db[\"youtube\"].to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7e4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efrem_27/Documents/github/AI_engineer_project/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"SQL analytics course with DuckDB - joins concepts\\n[00:00:00] Hello and welcome to this video where we'll go ~~into joins and going ~~into the concepts and intuition about joins that you later on can work with joins in code, which will be the next lecture. And for the coding part, we'll go into starting with some generating synthetic data to do joints to see a very simple case.\\nBut later on we'll move on to the Quila database and do joints over there to see how that looks like. But for this one, it's just a concept. We'll move into the slides directly.\\nKokchun Giang-1: Working with SQL, working with joints in SQL to combine columns from one or more tables. Note that we're talking about columns now except for when we're talking about cross join, which is a special case later on. But now we're talking about the columns here or we're actually talking about the columns in cross joints as well.\\n~~Sorry for that yes. ~~Before we talked about union or set operations and in set operations, we, we talk about rows, [00:01:00] right? Where join we are we're using compound queries. We're using several queries and compounding them together to get the, combining the results set of one with another, with a certain type of set operation.\\nBut for joint operations, we are combining the columns, not the rows. . That is very important. Joints in SQL explain with Venn diagrams here. We use Venn diagrams similar to the set operations. You'll see that they look very similar. Here we have inner join. This corresponds to the intersect for the set operations.\\nBut here we're using it is an intersect of the columns, right? It's the inner join here of column of table A and table B. Here, left join. You use everything that is from the left table table A and then the corresponding columns from the. B from table B there. And for the right joint we [00:02:00] pick the right table.\\nTable B here. And take corresponding rows for the corresponding columns for the table A and for full join, you combine all the columns. From both table A and B. Let's take a look. Here A and B are tables ~~and if, ~~and it's the columns that are joined. Let's take a look into example here.\\nThis is an example. ~~We have, ~~we combine two tables with left join. ~~Here you have a scale code for that. You pick out the, ~~you do from main dot plans. P and left ~~the ~~join with Main Plant Care PC on a certain type of column. ~~We, ~~here, we use Plant ID and we use PC plant id. One from P and one from pc.\\nHere you have plant id ~~here you have planned care. The ID here, actually it's a misspelling. It should be ID here and not plant id. Yes. ~~And then afterwards, when you have done the join you pick out the columns that you want. For example, ~~here, ~~I want plant ID from ~~PI ~~want plant name from ~~PI ~~want P type, right?\\nI want all this from P [00:03:00] and I want PC water schedule, and I want PC sunlight. ? It'll look like this. This is the matching column. You can see. ~~And ~~for P Plant id, this ~~is, you see here ~~is the matching column with this. ~~Or actually it's not the fault I saw. I said that I didn't see a plant ID here, it's actually correct.~~\\n~~We have plant ID here, ~~we have plant ID here. One corresponds to one. Three corresponds to three. Four corresponds to four, right? And then ~~we have five, and ~~we have two and five ~~also, ~~but they don't exist here, right? We will have a plant name and. ~~And the ~~type ~~four, ~~two, and five. But~~ those are not ~~they don't exist in the.\\nIn the right table, like in the planned care, which means that there will be null for water schedule and sunlight. Let's look into that. When we do left joint, and you can see they are null, right? Two and five are null. The other ones are joined according to left joint. It's ~~based on the left tables.~~\\n~~It's the ~~based on the left table, that is left joint. . Returns all records from left table and match with right table giving nulls in right columns if there's no [00:04:00] match. Null means basically it's missing value or not available or yeah, missing or not available. These are notes.\\nAnd here you can see, right? Join. Similarly, we have a matching column you can see here on the matching ones. But we use Right join instead and Right join. It's based on the right column. And that's why these three here become new. Returns all records from right table and match with left table.\\nGiving Nolls in left columns if there's no match. , These are notes and here we have Inner Join. Inner join, you can see we take those that are matching. Only one, three, and four will be matched. The rest are thrown away. That is inner Join. Intersection, right? It's the intersection of these two sets.\\nReturns all records where there is [00:05:00] a match in both tables. Hence no nos. And then we have full join which corresponds to the union in the set operations, right? Here we have a full join and it's this is the matching column as before, but we'll get all other plant IDs as well. But they will be nolls ~~where ~~where there are missing values, right?\\nReturns all records from both tables. If there's no match, nolls are used on non-matching table. Here we see that water schedule and sunlight. They don't exist for two and five. There are nulls and here the plant ID and plant name and type, they don't exist ~~in the in the ~~in the left one for yeah.\\nThey don't exist there. Why doesn't the six exist here? Yes, because we have picked here. P plant ID and not pc plant id. That's why it's missing the six here. [00:06:00] Nos, right? These are nos as well. , Then we got come into something called cross join in S scale, L in in Venn diagrams.\\nIt looks like this. You have all the rows here from table A and all the rows in table B. And it works like row a row row one. In table one is combined with. One and two. Row two is combined with one and two. Row three is combined with one and two, et cetera. This means that it would become something called a Cartesian product.\\nLet's look into that, how it looks and looks like this. If you have this the plant and you do the cross join plant and plant care, you do cross join and you'll see something like this. This is not the full list. This is not a full result. Instead you'll see here that you can see rose oak to lip, cactus, sunflower.\\nThese are the five from the plant, and it's combined with the first one here. You can see daily. [00:07:00] And the first one here, full sun. And then next one is rose will be combined with weekly. Weekly impartial sun, and then that, rose, tulip, cactus, sunflower.\\nThey're combined with weekly and ~~they're combined with ~~partial sun. And then later on ~~we have. ~~We have similarly here, like rose to sunflower. They're combined with biweekly and full sun, et cetera. Yes. Cross join, like right now, I just show you ~~how ~~how the result is. But there are actually quite nice application with cross joinin that for example when you want to.\\nUN nests un nests JSON structure json data, which actually I have~~ I have it in ~~in the appendix~~ a one appendix which is duct DB tricks, ~~where you'll see a case where I use the cross join to ~~actually unst. SKL ~~that ~~the J ~~data. That is quite cool. , Here you can see returns, ~~all records, joints all record joints.~~\\nAll rows from left table with all rows in right [00:08:00] table. That is how cross joints work. Yes.\\nin this video we have gone through SQL joints. They work in db, but they work in ~~other ~~other SQL languages as well. The concepts and intuition behind them, and I hope that~~ you, ~~you have also connected it to, set operations that we learned before and the set theory that you may have learned in mathematics.\\nNote that in~~ SKL ~~joints, it's about the columns while the set operations in s scale, they're about the rows. These are the difference, main difference that you should know about. And then we talk about different types of joints. We had ~~like ~~inner joint, we had left joint, right joint, and we also full.\\n~~Full ~~join and cross joins. These were a few joins that we talked about, and ~~you ~~as you saw in the slides, ~~there were some like, depend ~~depending on which type of joins you have, ~~you get, ~~you will get ~~like ~~null values~~ when, ~~when there's missing in ~~order ~~table, right? ~~This ~~I hope that you've learned a lot in this video and see you in the next one.\\nBye.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db[\"youtube\"].search(\"sql joins\").limit(3).to_list()[0][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cccb1452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"API trafiklab\\n[00:00:00] Hello and welcome to this video where we'll go into getting data from an API. And the API that we've chosen is Trafiklab. And from this API, you will be able to get data on public transport. \\nIt's good to, understand a little bit about the data set so that you could, for example, monitor if there's delays in the trams or trains. So yes moving on, we'll go into the web browser directly now.\\nSo here I'm in the web browser and I've gone into Trafiklab.\\nse slash API. Let me move myself here.\\nIn Traffic Lab SC slash api~~ we have ~~we have several APIs that we can work with. And~~ one, ~~the ones that we will pick are those that are in s robot. So here race robot stalled. It's tabella here. You can get the timetables for different stops.\\nSo we'll go in and ~~see ~~see more details, how to work with this one. [00:01:00] And this re robot plan is used for ~~planning~~ planning your trip. For example, you want to travel ~~from Sweden to ~~from UBO to Stockholm, ~~for example. ~~Ubo to Malmo. You can find out. ~~The trips~~ which type of trains and buses there are and their stops, et cetera.\\nSo this is quite interesting and it's an open API so that you can use it for free. The only thing you need to do is ~~to ~~to create an account and register ~~for ~~for these APIs to use. Firstly. ~~You, ~~if you scroll up here, there's Minna sidor or my pages. So clicking on this one we'll go in here and you can create an account for me, I will just log in with GitHub so that you can do if you have a GitHub.\\nAnd here~~ I have ~~you should create your own projects. So basically I have a few projects, I have streaming data and I have this testing and there's also a sandbox here. So you should create a new project.[00:02:00] \\nSo when creating a new project, you give it a name. I will give it a, for example, a travel planner, ~~for example, ~~and ~~you can have a homepage if ~~you can link to a homepage if you want, but if you don't, it's okay. You can choose what type of project it is. It's an educational project and open source repository if you have that.\\nBut~~ unless you don't need, ~~you don't need to. ~~And ~~description is also good to have or it's mandatory because these are optional. Description learning. Let's see. Learning. Lab a p. Same.\\nSo here ~~I have~~ I have the travel planner ~~and ~~and now you should get your API keys ~~and to get the ~~. It's basically like this. ~~You choose here~~ you choose which type of API you want. And the one we want to pick is a robot\\nme see here. Race robot version 2. 1. And then you click add key to project and you will get an [00:03:00] API key. \\nHere are the API keys. I won't go down to the API keys because I don't want to share them with you. Instead you should go down there and copy ~~that key~~ that specific key because we will use it ~~in order to get ~~in order to use this page~~ get the ~~APIs.\\nSo moving on to when you have the key store it in a dot ENV file, I'll show you how that looks soon. Or actually we can go there directly. I'll go to Visual Studio Code. And here~~ in this~~ in this project, I'll open a new terminal and let's see what I will do. I will do touch dot ENV.\\nSo that we get a dot ENV file and inside this dot ENV file, you should write API equals to your API key the ones that you've copied. So just copy and paste it here and then we'll go back to Visual Studio. And we'll go back to. Traffic [00:04:00] lab and inside of API keys or actually documentation.\\nYou've got the documentation and you're going to API overview, right here, and we can go into this robot started stability, for example, click on this one and here there is a example on how you call this one. So you basically just copy this one. Departures and arrivals, right? So you copy this one in order ~~to ~~to get the data from this one.\\nAnd, but then you need to create an if you're using Python, which we're using in this course, and in this lecture we will~~ we'll ~~use the request library and we will do a get request to this end point and using our API key. And also you can go down here to read a little bit more about different options and what they mean.\\nSo I won't go through them instead I will leave it to you for you to read. But let's go back to Visual Studio Code now [00:05:00] and let's set up different things. So let me do this. I will create the virtual environment. So uvvnv source dot. So now I've activated my virtual environment and I will do uv pipinstall.\\nWhat do I need? I need ipykernel, of course, because I will work with Jupyter Notebook. I also need pandas. And I also need And let me think, what do I need requests? I need yes, starting with this. I think not dot ENV of course. So Python dot ENV. One thing with env it is for so that you can store your secrets.\\nI'll show you what that means soon. So let's create a Jupyter notebook file now. So touch\\nlet me see touch [00:06:00] API, public transport, ipnb. Okay. And now we'll open this one.\\nSo we'll do an EDA on public transport traffic lab API. And then I'll change this to my virtual environment.\\nSo let's start with testing out our dot ENV. ~~So from dot, let me change this to Python and I'll increase it, making it a little bit bigger. ~~So from dot ENV import load dot ENV. And we need to import OS as well in order for us to get the environment variable and then we'll do import requests .\\nAnd starting with our load. dnv, we can do like this. Start with load. dnv. In general, you need to have a path here. But~~ in, ~~when you're in Jupyter Notebook, you have the path is based on where ~~this ~~this file is so since e NV is a sibling [00:07:00] to this file and this Jupiter notebook, ~~then~~ then do ENV will be found.\\nSo when we do low e nv and then we can do os get ENV, and we take the API, if we are going to nv, we can see that it's called, it's just called. I'll call it API key. And then I will do API key here. And if I run this one, we can see we get dot. That means that ~~we~~ the Jupyter Notebook finds this dot DNV.\\nOkay, great. So now I'll just pause the video and I'll put in my real key. So remember, the real key can be found ~~in ~~in strategic lab where you're logged in.\\nI've added my real key and of course I won't show that to you. It's important that you add do ENV ~~to your ~~to your.gi nor file. If it isn't there already, so that is to [00:08:00] make sure that it's not tracked by Git and that you don't accidentally push it to a public GitHub repository.\\nSo this is in order for us to so because we don't want to write out the API key here. Directly because when I push it~~ you ~~then people will see it ~~in my directory, ~~in my repository and can use my API key. So secrets store it in DNV and load it using Load d nv. Okay, so then this one, I can just call it API Key equals to this.\\nSo if I run this one it, it is stored in API key, but~~ I ~~I don't write it out so that you can't see what it is. However, I will use it later on. So now we'll go into Trafiklab. So here in Trafiklab, let me see. So in traffic lab we have if we go into our ~~this robot~~ [00:09:00] this robot route planner, you can start here and you can see this example call.\\nLet's copy this one. So it says. This example called ~~receive ~~retrieves all routes from Stockholm Central Station ~~seven~~ this ID to Malm Central Station, another ID. So I just copy this one and I go back to my Visual Studio code and I will call URL equals to this, make it into a string and make it into an F string.\\nAnd then I will also make this API key into a variable so that I can use this. API key inside of this URL. Okay so since we have, we can read it out here. So api. resrobot. se version 2. 1 slash trip. So ~~this is the end, so it's~~ it's the API. We query, we're using the format. This is an [00:10:00] option. The option is a format which is JSON.\\nAnd another option, origin ID equals to this ID. And dest ID is destination ID is this ID here. And then we have pass list equals true and show passing points equals true. Actually, I'm not sure what both of them are. ~~It's ~~it's listed in the documentation in the web page, which you can read about.\\nAnd then most important, very important, is that we have the access ID, which is our pass list. API key, right? So that is very important. And we get the API key from our dnv. So that is how everything is connected. So now we have our URL. So this is an endpoint for us to retrieve data. So in order for us to get the data we need to do requests dot get, and basically we just put in the URL.\\nAnd we call [00:11:00] this response equals to this response. And I run this one response 401. Why is that? Let me pause and I will pause and debug this.\\nOkay, I found a problem. First of all, I wrote response. txt to see~~ to see what~~ what text we get. And we get an error code, which says API auth, error text access denied. Okay, then I thought based on this, what could be the problem? Maybe the API key is wrong. So what did, ~~I just, ~~I typed out API key and saw what I get.\\nDot dot. How strange, even if I re ran this one, I got API key. Because this is already loaded, right? That is how it works in Jupyter Notebook. When it loads one time, it won't load again. So this is important if you have~~ if you ~~started with something else than ~~your API, ~~your real API key. Just do restart.\\n~~Restart this one, ~~and now I will [00:12:00] remove this cell here. And if I run this one, now it should work. Yes, now it works. We can see there's a response. txt, and we have Stockholm Central Station and a lot of things here. So instead of getting it as a text, I want to get it as a JSON object. ~~So as a JSON, ~~so JSON object is basically in Python is represented as a dictionary.\\nSo you have a dictionary of a list and you have a lot of other things. So in dictionaries, a very important thing what I usually do when I start working with API where I get JSON data is that I usually Try to explore this API, explore this dictionary. So starting with this, let's continue.\\nWe can do like this. Let's see. Response. json we can get let me see. Response. json, we can call it results,[00:13:00] \\nresponse. json, result, and we do result. keys, and we can see what type of keys we have. So we have trip, we have result status, and technical messages, server version, et cetera. So there's a lot of things here. And actually in my Jupyter notebook~~ in the. ~~In the lecture note, you can see that I've explored most of them, I think.\\nHowever, ~~you should also ~~you should also check them out. What we can do is like this. Since it's a dictionary, we can take out the trip here. And we can see that it's a list. It starts with brackets here. If it's a list, we can do like this. We can do length of this. And we can see seven.\\nOkay, there was seven here. We could do a result of result status and see what that is. Okay. ~~Some time diff ~~some kind of metadata. I'm not sure what this, ~~what it ~~is, but ~~you should, ~~you can read in the [00:14:00] documentation in case you wonder. We can continue here technical messages, and see what we get here.\\nOkay, so technical messages. We get ~~some, ~~something that I don't understand either. Let's continue going on down here and we'll take ~~serve ~~server version. Probably I can understand what that is. Dialect version plan R T S. I think those are not so relevant for us. So we will continue with the trip.\\nSo results of trip. So you can see here we have it's a list and now it's seven items, right? So what we can do with this is that we could ~~loop through it. So if it's a list, we can ~~loop through it. We can loop through the list. And actually in the lecture notes, I have created A function~~ of this ~~of the get request, basically.\\nSo that is a little bit [00:15:00] more elaborate and ~~you can~~ you can choose it to use. ~~And we can ~~however, here ~~I will I will not write, or ~~I can write out the function, actually. Because we will use it later on. Let's do that. Let's go into the function. I will create a function of it. I will just copy from the lecture note and I will explain that.\\nThis is what I did for the function. We can remove the API key as we had it earlier. So basically it's the same as before. We have a URL, however, the origin ID and destination ID I put it into as parameters so that you can send them in as arguments ~~in order ~~if you want to Choose other destinations and origins.\\nNow, the first one is Stockholm and the other one is Malm, but I want to get ~~the ~~just the body later on. So then afterwards we do a try ~~because how come? ~~Because the response object, the request. get, it can fail, right? It can fail with different [00:16:00] exceptions. And if it has an exception we also do response.\\nraise for status. So in case It'll raise an HTP error if it occurred. ~~Four, 400 x four xx and five xx. ~~So if you get status code 400 something, 500 something, then it's some kind of HTTP error. And that is what ~~I~~ we're catching here with the accept. So this one. Result equals getTrips and we can get result.\\nkeys. And this is basically the same ~~as~~ as I showed before. So now we have the trip, we get result of trip, right? So we can call this, let me see, we can call this we can call, for example exampleTrip equals to this one, and I will take the zero of it. Example trip of, so if I do example trip now, you can see that we get the first one.\\nSo origin [00:17:00] is in Stockholm and destination is in Gteborg, central Stockholm. Interesting. Yeah, I changed also here, this is another ID than the one I used before. So this one, this idea is for Gteborg, but how do we know which idea corresponds to which city or which stop? That, that will come back to later on in in the next section here, but we have Gteborg and Stockholm.\\nSo let's continue. We can we can figure out a little bit more things here. Here we can go into we can go in to example trip of for example we can go into distinct origin, and we can see that we get Stockholm and and it has these keys and these values. We can continue copy this one and go into example trip of destination.\\nAnd we can see that, okay, Gteborg Centralstation, et cetera, cool. [00:18:00] And you can explore more things here, but something I thought was quite interesting was so if you go into exampletrip.\\n~~key, exampletrip, ~~you can run this one. And you can see here, origin, destination, and we have service days. Actually, we can do exampleTrip. keys to find out what we have. So origin, destination, service days, legList is quite interesting. So I'll do legList. And this one, here we can see a lot of information. We have origin, we have destination.\\nSo we have several destinations, it seems. ~~So it seems to be, ~~so we have Stockholm here, and then we have Karlstad, so we can continue to find out different types of stops. ~~Leg list, and then we take out leg. ~~[00:19:00] Actually, ~~this ~~these names, I'm not sure what they stand for, but~~ they are in, ~~this is how they coded the response object.\\nSo we get the list here. This is quite interesting. So let's do length of this list. I want to see how many there are here. Okay. Two. I'll copy this one.\\nOkay. For example, I will pick the zero\\nand in the zero, we have origin destination. I can do dot he's. And we can see we have origin, destination, journey status, stop. It's quite interesting. So I'll continue, copy this one. I'll go [00:20:00] into stops. And we can see, okay, stops. We have some key called stop. And then there's a list here. Okay, so we'll pick that one, stop.\\nAnd we can see there's a list. Stockholm, Katrineholm, Hallsberg. Okay, see, ~~this is, ~~this requires some domain knowledge. ~~If you're ~~if you have traveled trains between Stockholm and Gteborg. These are common stations that exist there. So these are ~~the common stations or common, ~~the common stops, ~~though.~~\\nOkay, so this is quite interesting. So we could continue here and we could actually call for example, these are different stops, right? We could call it example stops, example, stops like this. And then I will loop through this one. So I will do like this. For stop [00:21:00] in example stops, and I can do stop dot get name.\\nSo basically get the same as using bracket notation. However, it won't return an error if the key is missing. Instead, it will give you none if the key is missing. So colon stop dot get for example, I will get the arrival time\\nor departure arrival time. Yeah, I could take departure time as well. Okay, let's see. Yeah, I need curly braces because I want to make a dictionary here. So basically I'm doing a list comprehension of the dictionary. So here we can see, okay, we started with Stockholm Central Station. We go into Katrineholm, Hallsberg, Degerfors, Kristinehamn and Karlstad.\\n~~Cool. ~~Cool. Maybe the other section, [00:22:00] because the length of these stops were two, right? And this ~~example stop that we, ~~example stops that we have, maybe this is half of the journey. I'm not sure this is worth finding out. Okay. But how did we get the body ~~as~~ as the stop as this as the ID, right?\\nSo this, we need to use ~~some, ~~another API. Called ResRobotStopLookup, so I will go ~~into here, ~~into the browser, and we can see in the browser, we have a stop lookup, and ~~the stop lookup, ~~it will basically, ~~so ~~you have here, this is the API, you have location. name, question mark, input equals just a body, And format equals ~~Jason.~~\\nAnd if you do ~~it, ~~the bar question mark, then you will, it's a ~~fussy ~~search so that it will match something that is similar to it. So basically here, you can see ~~what they said, like ~~the input ~~here, input as a, ~~as the option and [00:23:00] the search string, append the question mark for ~~fussy ~~search, that means we will find something ~~if we will find ~~for example, if we take.\\n~~If we just take, ~~without the question mark, we'll only get Gteborg here. This is the data we get. We get the ID, external ID, name, ~~and ~~longitude, latitude, etc. But with Fuzzy Search, ~~we'll get everything that, ~~we'll get things that are similar. ~~So we get Gteborg etc. ~~So everything with Gteborg is matched here.\\nOkay, cool. But then we find the external ID and then you use the external ID to put it into ~~your ~~your travel planner or your route planner or your ~~time ~~timetables. So moving back to Visual Studio Code.\\nOkay so let's go into the stop lookup API. Here, we have stop look up API. We use this to find the ID. I will copy the URL. And basically I can copy all of this [00:24:00] here. I'll change this to Python. And then, okay, if you look into What we did here. So location is just the body. I have an F string so that I search and get the body.\\nAnd this is a, an exact search. Now we don't have a question Mark and we have a API key and we have a result basically. So if I run this one,\\nwe get the stop location or cord location,\\nand we can do results let's see results of. Stop stop location or cord location. And I run this one and we can see here we have stop location\\nand you can see name is yet the body\\nand we can see, let's see, this is a list, right? So I can [00:25:00] do length of this list and it it contains 10 values. So basically, okay, we have 10 10 stops. Okay, so I will do result of, actually I will call this one, I'll remove this one like here, and I'll do stop locations equals to this, give it a variable, stop locations, and then I'll do stop locations, I'll run this one.\\nSo we have for example, zero, stopLocation zero, and we could take stopLocation zero of stopLocation, and we can dot, take dot keys, and we can see the keys here. Okay, so it has an external ID, and it has a name. That is interesting. So how, what if I do like this? I copy this one, and I take out [00:26:00] name.\\nCool. And if I copied this one and ~~I take out ~~I take out X ID, external ID, and we get, The external ID. So perfect. So this is how I got the ID for in order to put it into my route planner before. But if we have several, we want to pick the one that fits the best for us. Then basically ~~just ~~just do like this.\\nWe can loop through this. Let's do four, stop location, in stop locations. Remember that stop locations is a list. Stop locations is a list of ten values. And inside of stop locations there is, so when I look through it, I will get This value and then I will get 0, 1, 2, 3, 4, up to 10 or up to nine.\\nSo [00:27:00] here, this is a for loop and I want to have ~~stop location or stop equals ~~stop location or stop location, right?\\nAnd why do I do that? We can see that I did it here because that is how it was structured. So I needed to take this. guy and do get the stop location. And from the stop location, I need to find the name, right? So then I can print the stop of name and stop of external ID. So here you can see, here are all the IDs for Gteborg.\\nSo basically I can also do, I will do a little bit better formatting here. So print fString, stop,[00:28:00] \\nstop like this, and it should have a left alignment of 50 character wide field. This is what it means using fString formatting. And then afterwards, after these 50 characters, I want to have My next string. So my next string is external ID. So then I get stop here and I get the external ID here. And then I could left align these also.\\nSo that it comes into the external ID. So what I do is here stop. I need to do similar here. Like this, and I need to do it into F string like this,\\nlike this. If I run this [00:29:00] one, let's see. Yes, nothing happens, but if I do colon 50 character wide, and this means left alignment, other side means right alignment. So then, perfectly, now it's now it's easy for me to find out ~~which~~ which one I want. So if I want to have, for example Volkswagen, then I just pick this ID here.\\nOkay, great. And, yes, I've actually in my lecture note you should look into that. I have put it into a function which works. Which you can use for finding other locations that is actually quite good to have us as well. So I will copy that one. So this is from my lecture note, access ID from location.\\nSo you just type in the location and it will find bind it for you. And basically it's the same idea as before, however, ~~one important, ~~some important things here is that I use [00:30:00] so this is quite interesting. Okay, so this you have seen before you get the response object. And you get it as a JSON, you put it into try because there can be exceptions.\\nThen you do this for loop. And here is one important part, is that stopData equals to next of iter of stop. values.\\nThat is the logic. And then it has an except for for some errors. But with this one, you can just use this function immediately. So access ID from location. We can, for example, get Malm, and we're doing a fuzzy search so that we have here, we see Malm, and you can get the external ID, Malm, here, another ID.\\n~~You can~~ you can, for example, find a very small city here called Unsala. And you can see, yeah here's what's found in [00:31:00] Onsala. Actually, there's more stops in Onsala, but they don't have external IDs. And that's why ~~so ~~you can actually test it out without this if statement here. And ~~you will see ~~you will see more stations that corresponds to Unsala but~~ that, ~~that's why ~~I use this ~~I use this one in order for me to stop so that I can get the external ID because without the external ID, I cannot use it further anyway.\\nAnd also ~~I will for example, ~~I can find something else. This interesting is another small city. And you can see, yeah, there's a lot here. Okay. ~~But ~~perfect. Now ~~we have~~ we have this and we can move on to another API. We can move on to time tables. So in time tables, we go into this robot and we have time tables here.\\nAnd similarly, just copy this one here for departures and one for arrival. [00:32:00] You can pick the ones you want. ~~And let me. ~~Let me go up a little bit and find will actually go and copy. I ~~will ~~copy from my lecture note here. So this is for Korsvagen stop ID, because if I go up here, I have Gteborg Korsvagen is this ID.\\nI will copy this one.\\nAnd I go in here and store it. So this is the stop ID. I use this one to get the results I want. ~~And so you see it's another API endpoint. ~~And now actually I won't in this part, I won't put it into function, but~~ it's a, ~~it is good practice for you to put it into function ~~and ~~and do that and I will leave that for you to do.\\nInstead I will just pick out some, I will show you using a data frame. Now ~~the ~~import pandas as pd, [00:33:00] we could do like this. If we write out results. Results is a JSON object, right? That looks like this departure and it has a lot of other things. However, I'll just pick out the departure.\\nI'll actually throw this away because it will clutter my notebook. ~~When ~~otherwise I will do ~~the~~ the PD dot data frame of results of departure. That is where my data is. So df equals to this, df timetable, df timetable ~~dot~~ dot head, right? Head, like this, and you can see okay, so this is quite neat to work with.\\nIf you have a data frame, it's much neater than working ~~with~~ with the ~~Jason ~~objects directly.[00:34:00] \\nSo before we unnested the ~~Jason ~~objects and we looped through to get the things that we wanted, but now you can use the power of pandas and your panda skills in order to data process this. So basically you could do like this. dftimetable. columns for example. And we can see what ~~the ~~columns we have.\\n~~We could do dftimetable ~~We can pick out ~~we can, ~~for example, clean it so that for example, we want to pick out what do we want? We want name and we can see, yeah, ~~this is, ~~these are the names we could pick out. What do we want more? We could pick out the stop and we have all the stops here.\\nWe could pick out longitude, latitude, which you could use to draw in a map, dots in a map if you want. And see if you can map out the body direction [00:35:00] here, you can see where the directions are for the ~~trams on ~~trams and buses, we could ~~do ~~also ~~interesting in ~~which date we are using.\\nSo date okay. Six is today and we can see the time and yeah, I just accessed the data. So you can see that Yeah. Okay. Here is a time in around one hour, one hour time, and you can see that we have, okay, ~~one~~ 116 ~~buses and tra ~~buses and trams included~~ that ~~that the departures ~~from ~~from Kosh wagon.\\nOkay. So we could call this df timetable clean, for example. And then we could do DF timetable clean. And we could find out for example, name dot value counts. And we can see, yes, ~~these are the unique ones in ~~these are the unique buses and trams ~~in in ~~this station at this~~ station.~~\\nParticular time frame from ~~from seven, ~~1911 to [00:36:00] 2011. And you can see, yeah, these are the most common ones and yes, ~~they~~ you have uncommon ones ~~are ~~express bus. They are ~~come, they're flying or they're. ~~Going further away and fleet transfer means flight transfer. So they're also more uncommon?\\nYes. Okay. And with this~~ you, ~~you can do more exploratory data analysis, but I will leave that for you. So with this, I would like to thank you for watching this video and see you in the next one. Bye.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db[\"youtube\"].search(\"api trafiklab\").limit(3).to_list()[0][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874116c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "ASSETS_PATH = Path(__file__).absolute().parents[1] / \"assets\"\n",
    "\n",
    "def layout():\n",
    "\n",
    "    st.markdown(\"# Chatube\")\n",
    "    st.markdown(\"Ask a question regarding data engineering\")\n",
    "    text_input = st.text_input(label=\"Ask a questions\")\n",
    "\n",
    "    if st.button(\"Send\") and text_input.strip() != \"\":\n",
    "        response = requests.post(\n",
    "            \"http://127.0.0.1:8000/rag/query\", json={\"prompt\": text_input}\n",
    "        )\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        st.markdown(\"## Question:\")\n",
    "        st.markdown(text_input)\n",
    "\n",
    "        st.markdown(\"## Answer:\")\n",
    "        st.markdown(data[\"answer\"])\n",
    "\n",
    "        st.markdown(\"## Source:\")\n",
    "        st.markdown(data[\"filepath\"])\n",
    "\n",
    "        st.markdown(\"## Video:\")\n",
    "        video_path = ASSETS_PATH / \"example.mp4\"\n",
    "        st.video(str(video_path))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineer-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
